# AI Orchestrator Hub

A sophisticated **hybrid neural multiagent orchestration system** implementing advanced swarm intelligence with AI integration, adaptive learning, and comprehensive monitoring. **CPU-native, GPU-optional - built for the GPU-poor.**

[![Rust](https://img.shields.io/badge/rust-1.70+-orange.svg)](https://www.rust-lang.org)
[![TypeScript](https://img.shields.io/badge/typescript-5.6+-blue.svg)](https://www.typescriptlang.org)
[![Next.js](https://img.shields.io/badge/next.js-15.0+-black.svg)](https://nextjs.org)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![CI](https://github.com/do-ops885/ai-orchestrator-hub/actions/workflows/build.yml/badge.svg)](https://github.com/do-ops885/ai-orchestrator-hub/actions/workflows/build.yml)
[![GitHub issues](https://img.shields.io/github/issues/do-ops885/ai-orchestrator-hub)](https://github.com/do-ops885/ai-orchestrator-hub/issues)
[![GitHub stars](https://img.shields.io/github/stars/do-ops885/ai-orchestrator-hub)](https://github.com/do-ops885/ai-orchestrator-hub/stargazers)

## Table of Contents

- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Key Features](#key-features)
- [Quick Start](#quick-start)
- [Installation](#installation)
- [Configuration](#configuration)
- [API Documentation](#api-documentation)
- [Development](#development)
- [Deployment](#deployment)
- [Testing](#testing)
- [Contributing](#contributing)
- [Security](#security)
- [Troubleshooting](#troubleshooting)
- [License](#license)
- [Acknowledgments](#acknowledgments)

## Overview

The AI Orchestrator Hub is a cutting-edge implementation of swarm intelligence that combines neural processing, real-time communication, adaptive learning, and AI integration. Designed with a "CPU-native, GPU-optional" philosophy, it delivers maximum intelligence on minimal hardware while scaling to utilize advanced resources when available.

**Key Capabilities:**
- ü§ñ **Multiagent Swarm Intelligence** with adaptive coordination
- üß† **Hybrid Neural Processing** (basic NLP + optional FANN networks)
- üìä **Advanced Monitoring & Alerting** with predictive analytics
- üîÑ **Real-time Communication** via WebSocket with MCP protocol support
- üíæ **Intelligent Persistence** with state recovery and checkpointing
- üõ°Ô∏è **Enterprise Security** with rate limiting, auditing, and validation
- üöÄ **AI Integration** with OpenAI, Anthropic, and custom models
- ‚ö° **Performance Optimization** with circuit breakers and auto-scaling

## System Architecture

### Core Components

#### Backend (Rust)
- **Main Entry**: `backend/src/main.rs` - Enhanced Axum web server with advanced middleware
- **Hive Coordinator**: `backend/src/core/hive.rs` - Central orchestration with swarm intelligence
- **Agent System**: `backend/src/agents/` - Modular agent implementations with evolution and recovery
- **Task Management**: `backend/src/tasks/` - Advanced task scheduling with work stealing
- **Communication**: `backend/src/communication/` - WebSocket + MCP protocol support
- **Neural Processing**: `backend/src/neural/` - Adaptive learning with optional FANN networks
- **Infrastructure**: `backend/src/infrastructure/` - Monitoring, persistence, security, and optimization
- **MCP Server**: `backend/src/bin/mcp_server.rs` - Standalone Model Context Protocol server

#### Frontend (TypeScript/React/Next.js)
- **Dashboard**: `frontend/src/components/HiveDashboard.tsx` - Comprehensive monitoring interface
- **Visualization**: `frontend/src/components/SwarmVisualization.tsx` - Real-time 3D swarm display
- **Metrics**: `frontend/src/components/MetricsPanel.tsx` & `NeuralMetrics.tsx` - Advanced analytics
- **Resource Monitor**: `frontend/src/components/ResourceMonitor.tsx` - System resource tracking
- **State Management**: `frontend/src/store/hiveStore.ts` - Zustand store with real-time updates
- **Agent/Task Managers**: `frontend/src/components/AgentManager.tsx`, `TaskManager.tsx` - Full lifecycle management
- **AI Integration**: OpenAI, Anthropic SDK integration for enhanced capabilities

## Key Features

### Hybrid Neural Architecture - CPU-native, GPU-optional
- **Basic NLP** (default): Lightweight CPU processing for real-time swarm coordination
- **Advanced Neural** (optional): ruv-FANN integration for complex pattern recognition
- **AI Integration**: OpenAI, Anthropic SDK support for enhanced intelligence
- **Philosophy**: Built for the GPU-poor - maximum intelligence on minimal hardware
- **Feature Flags**: `basic-nlp`, `advanced-neural`, `gpu-acceleration`

### Advanced Agent System
- **Agent Types**: Worker, Coordinator, Specialist, Learner with evolution capabilities
- **Adaptive Learning**: Continuous improvement through experience and neural networks
- **Recovery System**: Automatic agent recovery and fault tolerance
- **Social Intelligence**: Agent relationships and collaborative learning
- **Capability Evolution**: Dynamic skill assessment and enhancement

### Intelligent Communication & Coordination
- **WebSocket**: Real-time bidirectional communication with heartbeat monitoring
- **MCP Protocol**: Model Context Protocol for external AI tool integration
- **Message Types**: Enhanced event system with structured logging
- **Rate Limiting**: API protection with configurable limits
- **Circuit Breaker**: Fault tolerance and graceful degradation

### Advanced Task Management
- **Priority Levels**: Low, Medium, High, Critical with dynamic adjustment
- **Work Stealing**: Efficient load balancing across agent pools
- **Status Tracking**: Comprehensive lifecycle monitoring with failure recovery
- **Capability Matching**: ML-enhanced agent assignment with performance prediction
- **Batch Processing**: Efficient handling of large task queues

### Enterprise Monitoring & Observability
- **Intelligent Alerting**: Predictive analytics with adaptive thresholds
- **Advanced Metrics**: Multi-dimensional performance tracking
- **Structured Logging**: JSON logging with security event tracking
- **Health Checks**: Comprehensive system health monitoring
- **Performance Optimization**: Auto-tuning with resource management

### Security & Compliance
- **Input Validation**: Comprehensive payload validation and sanitization
- **Security Auditing**: Detailed audit trails and compliance logging
- **Rate Limiting**: Configurable API protection
- **CORS Configuration**: Secure cross-origin resource sharing
- **JWT Authentication**: Optional authentication with role-based access

### Persistence & Reliability
- **Intelligent Persistence**: SQLite/PostgreSQL with compression and encryption
- **State Recovery**: Automatic checkpointing and crash recovery
- **Backup System**: Incremental backups with retention policies
- **Data Integrity**: Validation and consistency checks

## Quick Start

### Basic Setup (Recommended)
```bash
# Clone the repository
git clone https://github.com/do-ops885/ai-orchestrator-hub.git
cd ai-orchestrator-hub

# Backend with basic NLP
cd backend
cargo run

# Frontend (in new terminal)
cd ../frontend
npm install
npm run dev
```

### Advanced Features (Optional)
```bash
# Backend with advanced neural processing
cd backend
cargo run --features advanced-neural

# Run neural comparison demo
cargo run --features advanced-neural --example neural_comparison

# Run MCP server for external integrations
cargo run --bin mcp_server
```

## Ports & Endpoints
- **Backend API**: `http://localhost:3001`
- **Frontend Dashboard**: `http://localhost:3000`
- **WebSocket**: `ws://localhost:3001/ws`
- **MCP Server**: `http://localhost:3002` (when running standalone)
- **Health Check**: `http://localhost:3001/health`
- **Metrics**: `http://localhost:3001/metrics`

## API Endpoints
- **Agents**: `GET/POST /api/agents`, `GET/PUT/DELETE /api/agents/{id}`
- **Tasks**: `GET/POST /api/tasks`, `GET/PUT/DELETE /api/tasks/{id}`
- **Hive Status**: `GET /api/hive/status`, `GET /api/hive/metrics`
- **Resources**: `GET /api/resources` (system resource information)
- **Health**: `GET /health` (comprehensive health check)
- **Metrics**: `GET /metrics` (performance metrics)

## Data Structures

### Core Types
- **Agent**: ID, type, state, capabilities, position, energy, social connections
- **Task**: ID, description, priority, status, required capabilities, assigned agents
- **HiveStatus**: Metrics, swarm center, total energy, creation/update timestamps
- **SwarmMetrics**: Agent counts, task completion, performance, cohesion, learning progress

### Neural Processing
- **NLPProcessor**: Pattern recognition, semantic analysis, learning insights
- **HybridNeuralProcessor**: Optional FANN networks for advanced capabilities
- **NetworkType**: Basic, FANN, LSTM configurations

## Installation

### Prerequisites

- **Rust**: 1.70+ with Cargo
- **Node.js**: 18+ with npm
- **System Requirements**:
  - Minimum: 2GB RAM, 2 CPU cores
  - Recommended: 4GB RAM, 4+ CPU cores
  - Optimal: 8GB+ RAM, 8+ CPU cores with SIMD support

### Backend Setup

```bash
# Clone the repository
git clone https://github.com/do-ops885/ai-orchestrator-hub.git
cd ai-orchestrator-hub

# Install Rust dependencies and build
cd backend
cargo build

# Run with basic NLP (recommended for development)
cargo run

# Run with advanced neural features
cargo run --features advanced-neural

# Run MCP server for external integrations
cargo run --bin mcp_server
```

### Frontend Setup

```bash
# Install Node.js dependencies
cd frontend
npm install

# Start development server
npm run dev

# Build for production
npm run build
```

### MCP Server (Optional)

```bash
# Run standalone MCP server for external integrations
cd backend
cargo run --bin mcp_server
```

## Configuration

### Environment Variables

Create a `.env` file in the backend directory:

```env
# Server Configuration
HIVE_PORT=3001
HIVE_HOST=0.0.0.0
CORS_ORIGINS=http://localhost:3000

# Logging & Monitoring
LOG_LEVEL=info
LOG_FORMAT=json
METRICS_COLLECTION_INTERVAL_MS=5000
ALERT_CHECK_INTERVAL_MS=30000

# Neural Processing
NEURAL_MODE=basic
MAX_AGENTS=1000
TASK_QUEUE_SIZE=10000
LEARNING_RATE=0.01

# WebSocket & Communication
WS_MAX_CONNECTIONS=100
WS_HEARTBEAT_INTERVAL=30
WS_TIMEOUT_SECS=300

# Resource Management
MEMORY_LIMIT_MB=1024
CPU_CORES=auto
CPU_WARNING_THRESHOLD=70.0
MEMORY_WARNING_THRESHOLD=80.0

# Persistence
DATABASE_URL=./data/hive_persistence.db
PERSISTENCE_CHECKPOINT_INTERVAL_MINUTES=5
BACKUP_ENABLED=true

# Security
RATE_LIMIT_REQUESTS_PER_MINUTE=1000
JWT_SECRET=your-secret-key-here
AUDIT_LOGGING_ENABLED=true

# Performance
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_RECOVERY_TIMEOUT_MS=30000
PERFORMANCE_OPTIMIZATION_ENABLED=true
```

### Feature Flags

The system supports multiple build configurations:

- `default = ["basic-nlp"]`: Lightweight NLP processing
- `advanced-neural`: Enables ruv-FANN neural networks
- `gpu-acceleration`: GPU support (requires compatible hardware)

## API Documentation

### REST Endpoints

#### Agents Management
- `GET /api/agents` - List all agents with filtering and pagination
- `POST /api/agents` - Create a new agent with validation
- `GET /api/agents/{id}` - Get detailed agent information
- `PUT /api/agents/{id}` - Update agent configuration
- `DELETE /api/agents/{id}` - Remove agent with cleanup

#### Tasks Management
- `GET /api/tasks` - List tasks with status filtering
- `POST /api/tasks` - Create task with capability matching
- `GET /api/tasks/{id}` - Get task details and execution history
- `PUT /api/tasks/{id}` - Update task priority or cancel
- `DELETE /api/tasks/{id}` - Cancel and cleanup task

#### Hive Operations
- `GET /api/hive/status` - Comprehensive hive status and metrics
- `GET /api/hive/metrics` - Detailed performance metrics and trends
- `GET /api/resources` - System resource utilization
- `POST /api/hive/reset` - Reset hive state (development only)

#### System Management
- `GET /health` - Comprehensive health check with component status
- `GET /metrics` - Prometheus-compatible metrics endpoint

### WebSocket Events

Connect to `ws://localhost:3001/ws` for real-time updates:

- `hive_status`: Complete hive state, metrics, and swarm intelligence
- `agents_update`: Agent list with states, capabilities, and performance
- `metrics_update`: Real-time performance metrics and alerts
- `agent_created`: New agent creation with configuration details
- `agent_failed`: Agent failure notifications with recovery status
- `task_created`: New task creation with assignment details
- `task_completed`: Task completion with results and metrics
- `task_failed`: Task failure with error details and retry status
- `alert_triggered`: Intelligent alerting with predictive insights
- `resource_update`: System resource utilization updates
- `error`: Structured error notifications with context

### MCP (Model Context Protocol) Integration

The system implements MCP 1.0 for seamless AI tool integration:

#### Available Tools
- `create_swarm_agent`: Create agents with custom capabilities and behaviors
- `assign_swarm_task`: Distribute tasks with intelligent agent matching
- `get_swarm_status`: Retrieve comprehensive hive status and metrics
- `analyze_with_nlp`: Perform advanced NLP analysis using neural networks
- `coordinate_agents`: Trigger swarm coordination and formation optimization
- `get_performance_metrics`: Access detailed performance analytics
- `manage_resources`: Monitor and optimize system resource usage

#### Resources
- `hive://status`: Live system status with real-time updates
- `hive://agents`: Agent information with capability profiles
- `hive://tasks`: Task queue with execution status and history
- `hive://metrics`: Performance metrics and alerting data
- `hive://resources`: System resource utilization and optimization

#### Standalone MCP Server
Run the dedicated MCP server for external integrations:
```bash
cd backend
cargo run --bin mcp_server
```
Access at `http://localhost:3002` with WebSocket support at `ws://localhost:3002/ws`

## Testing

### Backend Testing

```bash
cd backend
cargo test                    # Basic tests
cargo test --features advanced-neural  # With neural features
cargo test --all-features     # All features enabled
cargo test --test integration_tests  # Integration tests
```

### Frontend Testing

```bash
cd frontend
npm test                      # Unit tests
npm run test:coverage         # Test coverage
npm run lint                  # ESLint checks
npm run build                 # Build verification
```

### Performance Benchmarks

| Configuration | Agents | Tasks/sec | Memory Usage | CPU Usage | Features |
|---------------|--------|-----------|--------------|-----------|----------|
| Basic NLP     | 100    | 50-75     | 256MB        | 15%       | Core swarm intelligence |
| Basic NLP     | 500    | 200-300   | 512MB        | 35%       | + Adaptive learning |
| Advanced Neural| 100   | 75-100    | 384MB        | 25%       | + FANN networks |
| Advanced Neural| 500   | 350-500   | 768MB        | 55%       | + Neural optimization |
| Full Featured | 1000   | 500-750   | 1.2GB        | 70%       | + Persistence, monitoring |
| High Performance| 5000  | 1000+     | 2.5GB        | 85%       | + GPU acceleration |

**System Requirements:**
- **Minimum**: 2GB RAM, 2 CPU cores, 1GB storage
- **Recommended**: 4GB RAM, 4+ CPU cores, 5GB storage
- **High Performance**: 8GB+ RAM, 8+ CPU cores, 10GB+ storage
- **GPU Optional**: CUDA-compatible GPU for neural acceleration

## Development

### Code Standards

- **Rust**: Follow Clippy rules with comprehensive linting
- **TypeScript**: Strict type checking with ESLint flat config
- **Documentation**: Use `///` for public APIs, `//!` for module docs
- **Testing**: Write unit tests for all public functions
- **Error Handling**: Use `anyhow::Result` for Rust, proper error boundaries for React

### Development Workflow

```bash
# Backend development
cd backend
cargo build                    # Build with default features
cargo run                      # Run basic version
cargo run --features advanced-neural  # Run with neural features

# Frontend development
cd frontend
npm install                    # Install dependencies
npm run dev                    # Start development server

# Linting and formatting
cargo clippy --all-features    # Comprehensive linting
cargo fmt --all                # Code formatting
npm run lint                   # Frontend linting
```

### Examples and Demos

```bash
# Neural processing demos
cargo run --features advanced-neural --example neural_comparison
cargo run --features advanced-neural --example advanced_neural_test
cargo run --features advanced-neural --example lstm_demo

# Agent system demos
cargo run --example adaptive_verification_demo
cargo run --example agent_monitor_example
cargo run --example pair_programming_demo

# Persistence and recovery
cargo run --example persistence_demo
cargo run --example advanced_persistence_demo

# Swarm intelligence
cargo run --example swarm_coordination_demo
```

## Deployment

### Production Build

```bash
# Backend
cd backend
cargo build --release

# Frontend
cd frontend
npm run build
```

### Docker Deployment

```dockerfile
# Example Dockerfile for backend
FROM rust:1.70 as builder
WORKDIR /app
COPY backend/ .
RUN cargo build --release

FROM debian:bookworm-slim
RUN apt-get update && apt-get install -y ca-certificates
COPY --from=builder /app/target/release/multiagent-hive /usr/local/bin/
EXPOSE 3001
CMD ["multiagent-hive"]
```

### Security Considerations

- Configure CORS policies for production domains
- Use HTTPS in production environments
- Implement rate limiting for API endpoints
- Monitor WebSocket connection limits
- Validate all input data
- Use secure environment variable management

## Security

We take security seriously. If you discover a security vulnerability, please:

- **Do not** create a public issue
- Use GitHub's [private vulnerability reporting](https://github.com/do-ops885/ai-orchestrator-hub/security/advisories/new)
- Or email: security@ai-orchestrator-hub.dev

For more information, see our [Security Policy](.github/SECURITY.MD).

## Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Workflow

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes and add tests
4. Run the test suite: `cargo test && npm test`
5. Run linting: `cargo clippy && npm run lint`
6. Commit your changes: `git commit -m 'Add amazing feature'`
7. Push to the branch: `git push origin feature/amazing-feature`
8. Open a Pull Request

### Code Review Process

- All changes require review from at least one maintainer
- Ensure all CI checks pass
- Update documentation for new features
- Add tests for bug fixes and new functionality

## Troubleshooting

### Common Issues

#### Backend Won't Start

```bash
# Check Rust version
rustc --version  # Should be 1.70+

# Clean and rebuild
cargo clean
cargo build

# Check for port conflicts
lsof -i :3001
```

#### Frontend Build Errors

```bash
# Clear node modules and reinstall
rm -rf node_modules package-lock.json
npm install

# Check Node.js version
node --version  # Should be 18+
```

#### WebSocket Connection Issues

- Ensure backend is running on port 3001
- Check firewall settings
- Verify CORS configuration in production

#### Performance Issues

- Monitor system resources with the ResourceMonitor component
- Consider using `advanced-neural` features for better performance
- Adjust `MAX_AGENTS` and `TASK_QUEUE_SIZE` in configuration

### Getting Help

- **GitHub Issues**: [Report bugs and request features](https://github.com/do-ops885/ai-orchestrator-hub/issues)
- **Documentation**: Comprehensive guides in [docs/](docs/) directory
- **Health Checks**: Use `/health` endpoint for system diagnostics
- **Logs**: Enable debug logging with `RUST_LOG=debug`
- **Community**: Join discussions and get help from the community

## Testing & Examples

### Available Examples

- **Neural Processing**:
  - `neural_comparison.rs` - Compare basic vs advanced neural processing
  - `advanced_neural_test.rs` - Test FANN neural network integration
  - `lstm_demo.rs` - Time series forecasting with LSTM networks

- **Agent System**:
  - `adaptive_verification_demo.rs` - Adaptive verification capabilities
  - `agent_monitor_example.rs` - Agent monitoring and metrics
  - `pair_programming_demo.rs` - Collaborative agent programming

- **Persistence & Recovery**:
  - `persistence_demo.rs` - Basic persistence functionality
  - `advanced_persistence_demo.rs` - Advanced state management

- **Swarm Intelligence**:
  - `swarm_coordination_demo.rs` - Swarm formation and coordination
  - `simple_verification_demo.rs` - Basic verification workflows

### Running Examples

```bash
# Neural processing examples
cargo run --features advanced-neural --example neural_comparison
cargo run --features advanced-neural --example advanced_neural_test
cargo run --features advanced-neural --example lstm_demo

# Agent system examples
cargo run --example adaptive_verification_demo
cargo run --example agent_monitor_example
cargo run --example pair_programming_demo

# Persistence examples
cargo run --example persistence_demo
cargo run --example advanced_persistence_demo

# Swarm intelligence
cargo run --example swarm_coordination_demo
cargo run --example simple_verification_demo
```

## Performance Benchmarks

| Configuration | Agents | Tasks/sec | Memory Usage | CPU Usage | Features |
|---------------|--------|-----------|--------------|-----------|----------|
| Basic NLP     | 100    | 50-75     | 256MB        | 15%       | Core swarm intelligence |
| Basic NLP     | 500    | 200-300   | 512MB        | 35%       | + Adaptive learning |
| Advanced Neural| 100   | 75-100    | 384MB        | 25%       | + FANN networks |
| Advanced Neural| 500   | 350-500   | 768MB        | 55%       | + Neural optimization |
| Full Featured | 1000   | 500-750   | 1.2GB        | 70%       | + Persistence, monitoring |
| High Performance| 5000  | 1000+     | 2.5GB        | 85%       | + GPU acceleration |

**System Requirements:**
- **Minimum**: 2GB RAM, 2 CPU cores, 1GB storage
- **Recommended**: 4GB RAM, 4+ CPU cores, 5GB storage
- **High Performance**: 8GB+ RAM, 8+ CPU cores, 10GB+ storage
- **GPU Optional**: CUDA-compatible GPU for neural acceleration

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **Core Technologies**: [Rust](https://www.rust-lang.org/) for performance and safety, [Tokio](https://tokio.rs/) for async runtime
- **Web Framework**: [Axum](https://github.com/tokio-rs/axum) for robust HTTP/WebSocket server
- **Frontend**: [Next.js](https://nextjs.org/) and [React](https://reactjs.org/) with [TypeScript](https://www.typescriptlang.org/)
- **Neural Processing**: ruv-FANN for advanced neural networks, custom NLP implementation
- **AI Integration**: [OpenAI SDK](https://github.com/openai/openai-node) and [Anthropic SDK](https://github.com/anthropics/anthropic-sdk-typescript)
- **Data Processing**: [Serde](https://serde.rs/) for serialization, [Petgraph](https://github.com/petgraph/petgraph) for graph algorithms
- **Database**: [rusqlite](https://github.com/rusqlite/rusqlite) for embedded persistence
- **Security**: [Ring](https://github.com/briansmith/ring) for cryptography, [jsonwebtoken](https://github.com/Keats/jsonwebtoken) for auth
- **Monitoring**: Custom metrics collection with [tracing](https://tracing.rs/) for observability
- **MCP Protocol**: [Model Context Protocol](https://modelcontextprotocol.io/) for AI tool integration
# TEST: GitHub Actions workflow test - Tue Sep  9 08:52:14 UTC 2025
