./backend/src/utils/auth.rs://! - JWT-based authentication with refresh tokens
./backend/src/utils/auth.rs://! - API key management for service-to-service communication
./backend/src/utils/auth.rs:    password_hash::{rand_core::OsRng, PasswordHash, PasswordHasher, PasswordVerifier, SaltString},
./backend/src/utils/auth.rs:use jsonwebtoken::{decode, encode, Algorithm, DecodingKey, EncodingKey, Header, Validation};
./backend/src/utils/auth.rs:    pub refresh_token: Option<String>,
./backend/src/utils/auth.rs:    pub key_id: String,
./backend/src/utils/auth.rs:    pub key_hash: String,
./backend/src/utils/auth.rs:    /// JWT encoding key
./backend/src/utils/auth.rs:    encoding_key: EncodingKey,
./backend/src/utils/auth.rs:    /// JWT decoding key
./backend/src/utils/auth.rs:    decoding_key: DecodingKey,
./backend/src/utils/auth.rs:    /// API keys
./backend/src/utils/auth.rs:    api_keys: Arc<RwLock<HashMap<String, ApiKey>>>,
./backend/src/utils/auth.rs:    /// Refresh token timeout
./backend/src/utils/auth.rs:        jwt_secret: &str,
./backend/src/utils/auth.rs:        let encoding_key = EncodingKey::from_secret(jwt_secret.as_ref());
./backend/src/utils/auth.rs:        let decoding_key = DecodingKey::from_secret(jwt_secret.as_ref());
./backend/src/utils/auth.rs:            encoding_key,
./backend/src/utils/auth.rs:            decoding_key,
./backend/src/utils/auth.rs:            api_keys: Arc::new(RwLock::new(HashMap::new())),
./backend/src/utils/auth.rs:    /// Hash an API key using Argon2id with OWASP-recommended parameters
./backend/src/utils/auth.rs:    fn hash_api_key(api_key: &str) -> HiveResult<String> {
./backend/src/utils/auth.rs:        let password_hash = argon2
./backend/src/utils/auth.rs:            .hash_password(api_key.as_bytes(), &salt)
./backend/src/utils/auth.rs:                reason: format!("Failed to hash API key: {e}"),
./backend/src/utils/auth.rs:        Ok(password_hash)
./backend/src/utils/auth.rs:    /// Verify an API key against a hash using Argon2id
./backend/src/utils/auth.rs:    fn verify_api_key(api_key: &str, hash: &str) -> HiveResult<bool> {
./backend/src/utils/auth.rs:            reason: format!("Invalid password hash format: {e}"),
./backend/src/utils/auth.rs:            .verify_password(api_key.as_bytes(), &parsed_hash)
./backend/src/utils/auth.rs:            refresh_token: Some(Uuid::new_v4().to_string()),
./backend/src/utils/auth.rs:        // Generate JWT token
./backend/src/utils/auth.rs:        let token = encode(&Header::default(), &claims, &self.encoding_key).map_err(|e| {
./backend/src/utils/auth.rs:        Ok((token, session_id))
./backend/src/utils/auth.rs:    /// Validate JWT token and return claims
./backend/src/utils/auth.rs:    pub async fn validate_token(&self, token: &str) -> HiveResult<Claims> {
./backend/src/utils/auth.rs:        let token_data = decode::<Claims>(token, &self.decoding_key, &validation).map_err(|e| {
./backend/src/utils/auth.rs:                reason: format!("Invalid JWT token: {e}"),
./backend/src/utils/auth.rs:        let claims = token_data.claims;
./backend/src/utils/auth.rs:    /// Refresh JWT token
./backend/src/utils/auth.rs:    pub async fn refresh_token(&self, refresh_token: &str) -> HiveResult<String> {
./backend/src/utils/auth.rs:        // Find session by refresh token
./backend/src/utils/auth.rs:            .find(|s| s.refresh_token.as_ref() == Some(&refresh_token.to_string()))
./backend/src/utils/auth.rs:                reason: "Invalid refresh token".to_string(),
./backend/src/utils/auth.rs:        // Generate new JWT token
./backend/src/utils/auth.rs:        let token = encode(&Header::default(), &claims, &self.encoding_key).map_err(|e| {
./backend/src/utils/auth.rs:        Ok(token)
./backend/src/utils/auth.rs:    /// Create API key for service authentication
./backend/src/utils/auth.rs:    pub async fn create_api_key(
./backend/src/utils/auth.rs:        let key_id = Uuid::new_v4().to_string();
./backend/src/utils/auth.rs:        let api_key = Uuid::new_v4().to_string();
./backend/src/utils/auth.rs:        let key_hash = Self::hash_api_key(&api_key)?;
./backend/src/utils/auth.rs:        let api_key_obj = ApiKey {
./backend/src/utils/auth.rs:            key_id: key_id.clone(),
./backend/src/utils/auth.rs:            key_hash,
./backend/src/utils/auth.rs:        let mut api_keys = self.api_keys.write().await;
./backend/src/utils/auth.rs:        api_keys.insert(key_id.clone(), api_key_obj);
./backend/src/utils/auth.rs:        Ok((key_id, api_key))
./backend/src/utils/auth.rs:    /// Validate API key
./backend/src/utils/auth.rs:    pub async fn validate_api_key(&self, api_key: &str) -> HiveResult<HashSet<Permission>> {
./backend/src/utils/auth.rs:        let mut api_keys = self.api_keys.write().await;
./backend/src/utils/auth.rs:        for (_, key_obj) in api_keys.iter_mut() {
./backend/src/utils/auth.rs:            if Self::verify_api_key(api_key, &key_obj.key_hash)? {
./backend/src/utils/auth.rs:                if let Some(expires_at) = key_obj.expires_at {
./backend/src/utils/auth.rs:                            reason: "API key expired".to_string(),
./backend/src/utils/auth.rs:                key_obj.last_used = Some(Utc::now());
./backend/src/utils/auth.rs:                key_obj.usage_count += 1;
./backend/src/utils/auth.rs:                return Ok(key_obj.permissions.clone());
./backend/src/utils/auth.rs:            reason: "Invalid API key".to_string(),
./backend/src/utils/auth.rs:            let Some(token) = auth_header else {
./backend/src/utils/auth.rs:                // Check for API key
./backend/src/utils/auth.rs:                if let Some(api_key) = req.headers().get("X-API-Key").and_then(|h| h.to_str().ok())
./backend/src/utils/auth.rs:                    match auth_manager.validate_api_key(api_key).await {
./backend/src/utils/auth.rs:            // Validate JWT token
./backend/src/utils/auth.rs:            match auth_manager.validate_token(token).await {
./backend/src/utils/auth.rs:        let (token, session_id) = auth_manager
./backend/src/utils/auth.rs:        assert!(!token.is_empty());
./backend/src/utils/auth.rs:        // Test token validation
./backend/src/utils/auth.rs:            .validate_token(&token)
./backend/src/utils/auth.rs:            .unwrap_or_else(|e| panic!("Failed to validate token: {e}"));
./backend/src/utils/auth.rs:        // Create API key
./backend/src/utils/auth.rs:        let (key_id, api_key) = auth_manager
./backend/src/utils/auth.rs:            .create_api_key(
./backend/src/utils/auth.rs:            .unwrap_or_else(|e| panic!("Failed to create API key: {e}"));
./backend/src/utils/auth.rs:        assert!(!key_id.is_empty());
./backend/src/utils/auth.rs:        assert!(!api_key.is_empty());
./backend/src/utils/auth.rs:        // Validate API key
./backend/src/utils/auth.rs:            .validate_api_key(&api_key)
./backend/src/utils/auth.rs:            .expect("Failed to validate API key");
./backend/src/utils/auth.rs:        let hash = AuthManager::hash_api_key(api_key).expect("Failed to hash API key");
./backend/src/utils/auth.rs:        // Verify the password against the hash
./backend/src/utils/auth.rs:            AuthManager::verify_api_key(api_key, &hash).expect("Failed to verify API key");
./backend/src/utils/auth.rs:        // Verify that wrong password fails
./backend/src/utils/auth.rs:            AuthManager::verify_api_key("wrong_password", &hash).expect("Failed to verify API key");
./backend/src/utils/auth.rs:        // Hash the same password multiple times
./backend/src/utils/auth.rs:        let hash1 = AuthManager::hash_api_key(api_key).expect("Failed to hash API key");
./backend/src/utils/auth.rs:        let hash2 = AuthManager::hash_api_key(api_key).expect("Failed to hash API key");
./backend/src/utils/auth.rs:            AuthManager::verify_api_key(api_key, &hash1).expect("Failed to verify API key");
./backend/src/utils/auth.rs:            AuthManager::verify_api_key(api_key, &hash2).expect("Failed to verify API key");
./backend/src/utils/structured_logging.rs:    pub fn with_data(mut self, key: &str, value: &str) -> Self {
./backend/src/utils/structured_logging.rs:            .insert(key.to_string(), value.to_string());
./backend/src/utils/error_handling.rs:    pub fn get_string(value: &Value, key: &str) -> HiveResult<String> {
./backend/src/utils/error_handling.rs:            .get(key)
./backend/src/utils/error_handling.rs:                field: key.to_string(),
./backend/src/utils/error_handling.rs:                reason: format!("Missing or invalid string field: {}", key),
./backend/src/utils/error_handling.rs:    pub fn get_number(value: &Value, key: &str) -> HiveResult<f64> {
./backend/src/utils/error_handling.rs:            .get(key)
./backend/src/utils/error_handling.rs:                field: key.to_string(),
./backend/src/utils/error_handling.rs:                reason: format!("Missing or invalid number field: {}", key),
./backend/src/utils/error_handling.rs:    pub fn get_boolean(value: &Value, key: &str) -> HiveResult<bool> {
./backend/src/utils/error_handling.rs:            .get(key)
./backend/src/utils/error_handling.rs:                field: key.to_string(),
./backend/src/utils/error_handling.rs:                reason: format!("Missing or invalid boolean field: {}", key),
./backend/src/utils/error_handling.rs:    pub fn get_array<'a>(value: &'a Value, key: &str) -> HiveResult<Vec<&'a Value>> {
./backend/src/utils/error_handling.rs:            .get(key)
./backend/src/utils/error_handling.rs:                field: key.to_string(),
./backend/src/utils/error_handling.rs:                reason: format!("Missing or invalid array field: {}", key),
./backend/src/utils/error_handling.rs:        key: &str,
./backend/src/utils/error_handling.rs:            .get(key)
./backend/src/utils/error_handling.rs:                field: key.to_string(),
./backend/src/utils/error_handling.rs:                reason: format!("Missing or invalid object field: {}", key),
./backend/src/utils/error_handling.rs:    pub fn get_optional_string(value: &Value, key: &str) -> Option<String> {
./backend/src/utils/error_handling.rs:            .get(key)
./backend/src/utils/error_handling.rs:    pub fn get_optional_number(value: &Value, key: &str) -> Option<f64> {
./backend/src/utils/error_handling.rs:        value.get(key).and_then(|v| v.as_f64())
./backend/src/utils/error_handling.rs:    pub fn get_optional_boolean(value: &Value, key: &str) -> Option<bool> {
./backend/src/utils/error_handling.rs:        value.get(key).and_then(|v| v.as_bool())
./backend/src/utils/validate_centralized_error_handling.rs:    // Test that key error types exist and can be created
./backend/src/utils/error.rs:    #[error("Cache error: {operation}, key: {key}, reason: {reason}")]
./backend/src/utils/error.rs:        key: String,
./backend/src/utils/error.rs:    #[error("Cache miss: {key}")]
./backend/src/utils/error.rs:    CacheMiss { key: String },
./backend/src/utils/error.rs:    #[error("Environment configuration missing: {envname}, required_key: {requiredkey}")]
./backend/src/utils/error.rs:        requiredkey: String,
./backend/src/utils/error.rs:    #[error("Secret management failed: {secretname}, operation: {operation}")]
./backend/src/utils/error.rs:        secretname: String,
./backend/src/utils/error.rs:        "Configuration override conflict: {overridekey}, source1: {source1}, source2: {source2}"
./backend/src/utils/error.rs:        overridekey: String,
./backend/src/utils/error.rs:    pub fn with_info(mut self, key: &str, value: &str) -> Self {
./backend/src/utils/error.rs:            .insert(key.to_string(), value.to_string());
./backend/src/utils/error_recovery.rs:        let key = format!("{}:{}", context.component, context.operation);
./backend/src/utils/error_recovery.rs:        history.entry(key).or_insert_with(Vec::new).push(result);
./backend/src/utils/error_recovery.rs:        let key = format!("{}:{}", context.component, context.operation);
./backend/src/utils/error_recovery.rs:        if let Some(results) = history.get(&key) {
./backend/src/utils/error_recovery.rs:    fn safe_get(&self, key: &str) -> HiveResult<&serde_json::Value>;
./backend/src/utils/error_recovery.rs:    fn safe_get_str(&self, key: &str) -> HiveResult<&str>;
./backend/src/utils/error_recovery.rs:    fn safe_get_u64(&self, key: &str) -> HiveResult<u64>;
./backend/src/utils/error_recovery.rs:    fn safe_get_f64(&self, key: &str) -> HiveResult<f64>;
./backend/src/utils/error_recovery.rs:    fn safe_get_bool(&self, key: &str) -> HiveResult<bool>;
./backend/src/utils/error_recovery.rs:    fn safe_get(&self, key: &str) -> HiveResult<&serde_json::Value> {
./backend/src/utils/error_recovery.rs:        self.get(key).ok_or_else(|| HiveError::ValidationError {
./backend/src/utils/error_recovery.rs:            field: key.to_string(),
./backend/src/utils/error_recovery.rs:    fn safe_get_str(&self, key: &str) -> HiveResult<&str> {
./backend/src/utils/error_recovery.rs:        self.safe_get(key)?
./backend/src/utils/error_recovery.rs:                field: key.to_string(),
./backend/src/utils/error_recovery.rs:    fn safe_get_u64(&self, key: &str) -> HiveResult<u64> {
./backend/src/utils/error_recovery.rs:        self.safe_get(key)?
./backend/src/utils/error_recovery.rs:                field: key.to_string(),
./backend/src/utils/error_recovery.rs:    fn safe_get_f64(&self, key: &str) -> HiveResult<f64> {
./backend/src/utils/error_recovery.rs:        self.safe_get(key)?
./backend/src/utils/error_recovery.rs:                field: key.to_string(),
./backend/src/utils/error_recovery.rs:    fn safe_get_bool(&self, key: &str) -> HiveResult<bool> {
./backend/src/utils/error_recovery.rs:        self.safe_get(key)?
./backend/src/utils/error_recovery.rs:                field: key.to_string(),
./backend/src/utils/config.rs:        for (key, value) in override_config.component_health_scores {
./backend/src/utils/config.rs:            merged_health_scores.insert(key, value);
./backend/src/utils/config.rs:        for (key, value) in override_config.component_issues {
./backend/src/utils/config.rs:            merged_issues.insert(key, value);
./backend/src/utils/config.rs:        for (key, value) in override_config.component_recommendations {
./backend/src/utils/config.rs:            merged_recommendations.insert(key, value);
./backend/src/agents/collaborative_learning.rs:            &problem_data.keywords,
./backend/src/agents/collaborative_learning.rs:                format!("Collaborative solution for: {}", problem_data.keywords.join(", ")),
./backend/src/agents/collaborative_learning.rs:                problem_data.keywords.clone(),
./backend/src/agents/collaborative_learning.rs:        problem_keywords: &[String],
./backend/src/agents/collaborative_learning.rs:            for keyword in problem_keywords {
./backend/src/agents/collaborative_learning.rs:                if knowledge.content.to_lowercase().contains(&keyword.to_lowercase()) {
./backend/src/agents/collaborative_learning.rs:                    if tag.to_lowercase().contains(&keyword.to_lowercase()) {
./backend/src/agents/collaborative_learning.rs:        assert!(system.knowledge_base.contains_key(&knowledge_id));
./backend/src/agents/collaborative_learning.rs:        assert!(system.active_sessions.contains_key(&session_id));
./backend/src/agents/agent.rs:                let tokens: Vec<String> = insight
./backend/src/agents/agent.rs:                let sentiment = nlp_processor.analyze_sentiment(&tokens);
./backend/src/agents/agent.rs:                let pattern_key = format!(
./backend/src/agents/agent.rs:                    .get(&pattern_key)
./backend/src/agents/agent.rs:                    .insert(pattern_key, new_strength.clamp(-1.0, 1.0));
./backend/src/agents/skill_evolution.rs:            let agent_id = *agent_entry.key();
./backend/src/agents/skill_evolution.rs:                    .keys()
./backend/src/agents/simple_verification.rs:    KeywordPresence { keywords: Vec<String> },
./backend/src/agents/simple_verification.rs:                RuleType::KeywordPresence { keywords } => {
./backend/src/agents/simple_verification.rs:                    SimpleVerificationSystem::check_keyword_presence(
./backend/src/agents/simple_verification.rs:                        keywords,
./backend/src/agents/simple_verification.rs:                    SimpleVerificationSystem::check_keyword_absence(
./backend/src/agents/simple_verification.rs:                RuleType::KeywordPresence { keywords } => {
./backend/src/agents/simple_verification.rs:                    SimpleVerificationSystem::check_keyword_presence(
./backend/src/agents/simple_verification.rs:                        keywords,
./backend/src/agents/simple_verification.rs:                    SimpleVerificationSystem::check_keyword_absence(
./backend/src/agents/simple_verification.rs:                    tokens: output.split_whitespace().map(str::to_string).collect(),
./backend/src/agents/simple_verification.rs:                    keywords: Vec::new(),
./backend/src/agents/simple_verification.rs:                tokens: goal.split_whitespace().map(str::to_string).collect(),
./backend/src/agents/simple_verification.rs:                keywords: Vec::new(),
./backend/src/agents/simple_verification.rs:        let tokens: Vec<String> = output.split_whitespace().map(str::to_string).collect();
./backend/src/agents/simple_verification.rs:        let sentiment = self.nlp_processor.analyze_sentiment(&tokens);
./backend/src/agents/simple_verification.rs:    fn check_keyword_presence(
./backend/src/agents/simple_verification.rs:        keywords: &[String],
./backend/src/agents/simple_verification.rs:        let mut found_keywords = 0;
./backend/src/agents/simple_verification.rs:        for keyword in keywords {
./backend/src/agents/simple_verification.rs:            if output_lower.contains(&keyword.to_lowercase()) {
./backend/src/agents/simple_verification.rs:                found_keywords += 1;
./backend/src/agents/simple_verification.rs:        let score = f64::from(found_keywords) / keywords.len() as f64;
./backend/src/agents/simple_verification.rs:            let missing_keywords: Vec<String> = keywords
./backend/src/agents/simple_verification.rs:                .filter(|keyword| !output_lower.contains(&keyword.to_lowercase()))
./backend/src/agents/simple_verification.rs:                description: format!("Missing required keywords: {}", missing_keywords.join(", ")),
./backend/src/agents/simple_verification.rs:                suggestion: Some("Include all required keywords in the output".to_string()),
./backend/src/agents/simple_verification.rs:    fn check_keyword_absence(
./backend/src/agents/simple_verification.rs:        let tier_key = format!("{:?}", result.verification_tier);
./backend/src/agents/simple_verification.rs:        *metrics.tier_usage.entry(tier_key).or_insert(0) += 1;
./backend/src/agents/verification_engine.rs:        self.strategies.keys().cloned().collect()
./backend/src/agents/verification_engine.rs:        let goal_tokens: Vec<String> = original_goal.split_whitespace()
./backend/src/agents/verification_engine.rs:        let result_tokens: Vec<String> = result_output.split_whitespace()
./backend/src/agents/verification_engine.rs:        let goal_sentiment = self.nlp_processor.analyze_sentiment(&goal_tokens);
./backend/src/agents/verification_engine.rs:        let result_sentiment = self.nlp_processor.analyze_sentiment(&result_tokens);
./backend/src/agents/verification_engine.rs:        // Calculate keyword overlap
./backend/src/agents/verification_engine.rs:        let goal_keywords: std::collections::HashSet<_> = goal_tokens.iter().collect();
./backend/src/agents/verification_engine.rs:        let result_keywords: std::collections::HashSet<_> = result_tokens.iter().collect();
./backend/src/agents/verification_engine.rs:        let intersection_size = goal_keywords.intersection(&result_keywords).count();
./backend/src/agents/verification_engine.rs:        let union_size = goal_keywords.union(&result_keywords).count();
./backend/src/agents/verification_engine.rs:        let keyword_overlap = if union_size > 0 {
./backend/src/agents/verification_engine.rs:        let alignment_score = (sentiment_alignment * 0.4) + (keyword_overlap * 0.6);
./backend/src/agents/verification_engine.rs:        debug!("Goal alignment analysis: sentiment={:.3}, keywords={:.3}, total={:.3}",
./backend/src/agents/verification_engine.rs:               sentiment_alignment, keyword_overlap, alignment_score);
./backend/src/agents/memory.rs:            learned_strategy: Some("focus on key patterns".to_string()),
./backend/src/agents/adaptive_verification.rs:            .flat_map(|outcome| outcome.rule_thresholds_used.keys())
./backend/src/agents/adaptive_verification.rs:            .filter(|outcome| outcome.rule_thresholds_used.contains_key(rule_id))
./backend/src/agents/adaptive_verification.rs:            .filter(|outcome| outcome.rule_thresholds_used.contains_key(rule_id))
./backend/src/agents/agent_evolution.rs:        let species_key = self.determine_species(&genome);
./backend/src/agents/agent_evolution.rs:            .entry(species_key)
./backend/src/agents/agent_evolution.rs:            let species_key = self.determine_species(genome);
./backend/src/agents/agent_evolution.rs:            let species_size = self.species_registry.get(&species_key).map(|v| v.len()).unwrap_or(1);
./backend/src/agents/agent_evolution.rs:        assert!(system.genomes.contains_key(&agent.id));
./backend/src/agents/verification_strategies.rs:        let tokens: Vec<String> = original_goal.split_whitespace()
./backend/src/agents/verification_strategies.rs:        // Extract key verbs (action words)
./backend/src/agents/verification_strategies.rs:        let actions: Vec<String> = tokens.iter()
./backend/src/agents/verification_strategies.rs:            .filter(|token| action_words.contains(&token.as_str()))
./backend/src/agents/verification_strategies.rs:        // Extract key nouns (target objects)
./backend/src/agents/verification_strategies.rs:        let targets: Vec<String> = tokens.iter()
./backend/src/agents/verification_strategies.rs:            .filter(|token| target_indicators.contains(&token.as_str()))
./backend/src/communication/protocols.rs:    pub fn with_metadata(mut self, key: String, value: serde_json::Value) -> Self {
./backend/src/communication/protocols.rs:        self.metadata.insert(key, value);
./backend/src/communication/patterns.rs:    pub async fn get_connection(&self, key: &str) -> CommunicationResult<CommunicationChannel> {
./backend/src/communication/patterns.rs:        if let Some(channel) = connections.get(key) {
./backend/src/communication/patterns.rs:            reason: format!("Connection not found for key: {}", key),
./backend/src/communication/patterns.rs:    pub async fn add_connection(&self, key: String, channel: CommunicationChannel) {
./backend/src/communication/patterns.rs:        connections.insert(key, channel);
./backend/src/communication/patterns.rs:    pub async fn remove_connection(&self, key: &str) {
./backend/src/communication/patterns.rs:        connections.remove(key);
./backend/src/communication/mcp.rs:            "keywords": text.split_whitespace().take(5).collect::<Vec<_>>(),
./backend/src/neural/nlp.rs:    pub keywords: Vec<String>,
./backend/src/neural/nlp.rs:        let tokens = self.tokenize(text);
./backend/src/neural/nlp.rs:        let semantic_vector = self.generate_semantic_vector(&tokens).await;
./backend/src/neural/nlp.rs:        let sentiment = self.analyze_sentiment(&tokens);
./backend/src/neural/nlp.rs:        let keywords = self.extract_keywords(text, 5).await;
./backend/src/neural/nlp.rs:        let patterns = self.identify_patterns(&tokens).await;
./backend/src/neural/nlp.rs:            tokens,
./backend/src/neural/nlp.rs:            keywords,
./backend/src/neural/nlp.rs:        self.update_vocabulary(&processed_input.tokens, success)
./backend/src/neural/nlp.rs:        self.update_vocabulary(&processed_output.tokens, success)
./backend/src/neural/nlp.rs:                    pattern.keywords.join(" "),
./backend/src/neural/nlp.rs:                    pattern.keywords.join(" ")
./backend/src/neural/nlp.rs:    fn tokenize(&self, text: &str) -> Vec<String> {
./backend/src/neural/nlp.rs:    async fn generate_semantic_vector(&self, tokens: &[String]) -> SemanticVector {
./backend/src/neural/nlp.rs:        for (i, token) in tokens.iter().enumerate() {
./backend/src/neural/nlp.rs:            let weight = vocabulary.get(token).copied().unwrap_or(0.1);
./backend/src/neural/nlp.rs:            let index = (token.len() + i) % dimensions.len();
./backend/src/neural/nlp.rs:    pub fn analyze_sentiment(&self, tokens: &[String]) -> f64 {
./backend/src/neural/nlp.rs:        let positive_count = tokens
./backend/src/neural/nlp.rs:            .filter(|token| positive_words.contains(&token.as_str()))
./backend/src/neural/nlp.rs:        let negative_count = tokens
./backend/src/neural/nlp.rs:            .filter(|token| negative_words.contains(&token.as_str()))
./backend/src/neural/nlp.rs:    pub async fn extract_keywords(&self, text: &str, limit: usize) -> Vec<String> {
./backend/src/neural/nlp.rs:        let tokens: Vec<String> = text
./backend/src/neural/nlp.rs:        let mut keyword_scores: Vec<(String, f64)> = tokens
./backend/src/neural/nlp.rs:            .map(|token| {
./backend/src/neural/nlp.rs:                let score = vocabulary.get(token).copied().unwrap_or(0.1);
./backend/src/neural/nlp.rs:                (token.clone(), score)
./backend/src/neural/nlp.rs:        keyword_scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
./backend/src/neural/nlp.rs:        keyword_scores
./backend/src/neural/nlp.rs:    async fn identify_patterns(&self, tokens: &[String]) -> Vec<Uuid> {
./backend/src/neural/nlp.rs:                .keywords
./backend/src/neural/nlp.rs:                .filter(|keyword| tokens.contains(keyword))
./backend/src/neural/nlp.rs:            if matches as f64 / pattern.keywords.len() as f64 > 0.5 {
./backend/src/neural/nlp.rs:    async fn update_vocabulary(&self, tokens: &[String], success: bool) {
./backend/src/neural/nlp.rs:        for token in tokens {
./backend/src/neural/nlp.rs:            let current_score = vocabulary.get(token).copied().unwrap_or(0.5);
./backend/src/neural/nlp.rs:            vocabulary.insert(token.clone(), new_score);
./backend/src/neural/nlp.rs:            keywords: input.keywords.clone(),
./backend/src/neural/nlp.rs:        let key = input.keywords.join("_");
./backend/src/neural/nlp.rs:        patterns.insert(key, pattern);
./backend/src/neural/nlp.rs:            keywords: input.keywords.clone(),
./backend/src/neural/nlp.rs:        let key = input.keywords.join("_");
./backend/src/neural/nlp.rs:        patterns.insert(key, pattern);
./backend/src/neural/nlp.rs:                input.keywords.join(" "),
./backend/src/neural/nlp.rs:                output.keywords.join(" ")
./backend/src/neural/nlp.rs:            .keywords
./backend/src/neural/nlp.rs:            .filter(|keyword| processed.keywords.contains(keyword))
./backend/src/neural/nlp.rs:        matches as f64 / pattern.keywords.len() as f64 > 0.3
./backend/src/neural/nlp.rs:        let tokens = self.tokenize(text);
./backend/src/neural/nlp.rs:        self.generate_semantic_vector(&tokens).await
./backend/src/neural/nlp.rs:    pub tokens: Vec<String>,
./backend/src/neural/nlp.rs:    pub keywords: Vec<String>,
./backend/src/neural/adaptive_learning.rs:        features.push(processed_text.tokens.len() as f64);
./backend/src/neural/adaptive_learning.rs:        features.push(processed_text.keywords.len() as f64);
./backend/src/core/hive/metrics_collection/events.rs:                .max_by_key(|(_, &count)| count)
./backend/src/core/hive/metrics_collection/collector.rs:    /// and alerting purposes. Uses string keys for flexibility.
./backend/src/core/hive/metrics_collection/collector.rs:        let event_key = format!("agent_{}", event_type);
./backend/src/core/hive/metrics_collection/collector.rs:            *counters.entry(event_key).or_insert(0) += 1;
./backend/src/core/hive/task_management_legacy/analytics.rs:        // Extract key metrics
./backend/src/core/hive/agent_management/lifecycle.rs:                let agent_id = *entry.key();
./backend/src/core/hive/agent_management/metrics.rs:        let metrics_key = CacheKey::AgentMetrics(agent_id);
./backend/src/core/hive/agent_management/metrics.rs:        if let Err(e) = self.cache_manager.invalidate_key(&metrics_key).await {
./backend/src/core/hive/agent_management/metrics.rs:            .map(|entry| (*entry.key(), entry.value().performance_score))
./backend/src/core/hive/agent_management/registry.rs:        let cache_key = CacheKey::Agent(agent_id);
./backend/src/core/hive/agent_management/registry.rs:        if let Err(e) = self.cache_manager.set_cached(cache_key, cache_entry).await {
./backend/src/core/hive/agent_management/registry.rs:        let cache_key = CacheKey::Agent(agent_id);
./backend/src/core/hive/agent_management/registry.rs:        if let Some(agent) = self.cache_manager.get_cached(&cache_key).await {
./backend/src/core/hive/agent_management/registry.rs:            if let Err(e) = self.cache_manager.set_cached(cache_key, cache_entry).await {
./backend/src/core/hive/agent_management/registry.rs:            .map(|entry| (*entry.key(), entry.value().clone()))
./backend/src/core/hive/agent_management/registry.rs:        self.agents.contains_key(&agent_id)
./backend/src/core/hive/background_processes.rs:        assert!(config.contains_key("work_stealing_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config.contains_key("learning_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config.contains_key("swarm_coordination_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config.contains_key("metrics_collection_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config.contains_key("resource_monitoring_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config_obj.contains_key("work_stealing_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config_obj.contains_key("learning_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config_obj.contains_key("swarm_coordination_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config_obj.contains_key("metrics_collection_interval_ms"));
./backend/src/core/hive/background_processes.rs:        assert!(config_obj.contains_key("resource_monitoring_interval_ms"));
./backend/src/core/hive/task_management/task_executor.rs:            .keys()
./backend/src/core/hive/task_management/mod.rs:// Re-export key components
./backend/src/core/auto_scaling.rs:                candidates.sort_by_key(|(_, agent)| agent.memory.experiences.len());
./backend/src/core/auto_scaling.rs:                candidates.sort_by_key(|(_, agent)| agent.capabilities.len());
./backend/src/core/swarm_intelligence.rs:            let type_key = std::mem::discriminant(&agent.agent_type);
./backend/src/core/swarm_intelligence.rs:            if !agent_types_used.contains(&type_key) || selected.len() < 3 {
./backend/src/core/swarm_intelligence.rs:                agent_types_used.insert(type_key);
./backend/src/init.rs:    // Load encryption key from secure sources
./backend/src/init.rs:    let encryption_key = PersistenceManager::load_encryption_key();
./backend/src/init.rs:    let encryption_enabled = encryption_key.is_some();
./backend/src/init.rs:        info!("ðŸ” Encryption enabled with secure key management");
./backend/src/init.rs:        encryption_key,
./backend/src/tasks/work_stealing_queue.rs:            let agent_id = *entry.key();
./backend/src/tasks/work_stealing_queue.rs:            let agent_id = *entry.key();
./backend/src/tasks/task.rs:    pub fn with_context(mut self, key: String, value: String) -> Self {
./backend/src/tasks/task.rs:        self.context.insert(key, value);
./backend/src/infrastructure/cached_query.rs:/// Cache key types for different data entities
./backend/src/infrastructure/cached_query.rs:    /// Custom key for flexible caching
./backend/src/infrastructure/cached_query.rs:            CacheKey::SystemStatus(key) => write!(f, "system_status:{}", key),
./backend/src/infrastructure/cached_query.rs:            CacheKey::PerformanceMetrics(key) => write!(f, "performance_metrics:{}", key),
./backend/src/infrastructure/cached_query.rs:            CacheKey::Custom(key) => write!(f, "custom:{}", key),
./backend/src/infrastructure/cached_query.rs:        key: CacheKey,
./backend/src/infrastructure/cached_query.rs:        if let Some(cached_value) = self.get_cached(&key).await {
./backend/src/infrastructure/cached_query.rs:            debug!("Cache hit for key: {}", key);
./backend/src/infrastructure/cached_query.rs:        debug!("Cache miss for key: {}, executing query", key);
./backend/src/infrastructure/cached_query.rs:        self.set_cached(key.clone(), cache_entry).await?;
./backend/src/infrastructure/cached_query.rs:    pub async fn get_cached<T>(&self, key: &CacheKey) -> Option<T>
./backend/src/infrastructure/cached_query.rs:        let cache_key = key.to_string();
./backend/src/infrastructure/cached_query.rs:        if let Some(value) = self.cache_manager.get(&cache_key).await {
./backend/src/infrastructure/cached_query.rs:                if self.is_entry_valid(&entry, key).await {
./backend/src/infrastructure/cached_query.rs:                    self.invalidate_key(key).await;
./backend/src/infrastructure/cached_query.rs:    pub async fn set_cached<T>(&self, key: CacheKey, entry: CacheEntry<T>) -> HiveResult<()>
./backend/src/infrastructure/cached_query.rs:        let cache_key = key.to_string();
./backend/src/infrastructure/cached_query.rs:        self.cache_manager.set(cache_key, cache_value).await?;
./backend/src/infrastructure/cached_query.rs:            tracker.insert(key, entry.version);
./backend/src/infrastructure/cached_query.rs:    /// Invalidate a specific cache key
./backend/src/infrastructure/cached_query.rs:    pub async fn invalidate_key(&self, key: &CacheKey) -> HiveResult<()> {
./backend/src/infrastructure/cached_query.rs:        let _cache_key = key.to_string();
./backend/src/infrastructure/cached_query.rs:        debug!("Invalidating cache key: {}", key);
./backend/src/infrastructure/cached_query.rs:            tracker.remove(key);
./backend/src/infrastructure/cached_query.rs:        // Get all keys that depend on this dependency
./backend/src/infrastructure/cached_query.rs:        let keys_to_invalidate: Vec<CacheKey> = {
./backend/src/infrastructure/cached_query.rs:            tracker.keys().cloned().collect()
./backend/src/infrastructure/cached_query.rs:        for key in keys_to_invalidate {
./backend/src/infrastructure/cached_query.rs:            if let Some(cached_value) = self.cache_manager.get(&key.to_string()).await {
./backend/src/infrastructure/cached_query.rs:                                    self.invalidate_key(&key).await;
./backend/src/infrastructure/cached_query.rs:    /// Bulk invalidate multiple keys
./backend/src/infrastructure/cached_query.rs:    pub async fn invalidate_keys(&self, keys: &[CacheKey]) {
./backend/src/infrastructure/cached_query.rs:        for key in keys {
./backend/src/infrastructure/cached_query.rs:            self.invalidate_key(key).await;
./backend/src/infrastructure/cached_query.rs:    pub async fn warm_cache<F, Fut, T>(&self, keys: Vec<CacheKey>, fetcher: F) -> HiveResult<()>
./backend/src/infrastructure/cached_query.rs:        info!("Starting cache warming for {} keys", keys.len());
./backend/src/infrastructure/cached_query.rs:        for key in keys {
./backend/src/infrastructure/cached_query.rs:            let key_clone = key.clone();
./backend/src/infrastructure/cached_query.rs:            debug!("Would prefetch data for key: {}", key);
./backend/src/infrastructure/cached_query.rs:    async fn is_entry_valid<T>(&self, entry: &CacheEntry<T>, key: &CacheKey) -> bool {
./backend/src/infrastructure/cached_query.rs:                if let Some(current_version) = tracker.get(key) {
./backend/src/infrastructure/cached_query.rs:                    if !tracker.contains_key(dep) {
./backend/src/infrastructure/cached_query.rs:        query_key: String,
./backend/src/infrastructure/cached_query.rs:            if let Some(execution) = deduplication.get(&query_key) {
./backend/src/infrastructure/cached_query.rs:            query_key: query_key.clone(),
./backend/src/infrastructure/cached_query.rs:            deduplication.insert(query_key.clone(), execution.clone());
./backend/src/infrastructure/cached_query.rs:            analyzer.record_execution(&query_key, execution_time);
./backend/src/infrastructure/cached_query.rs:        let query_key_clone = query_key.clone();
./backend/src/infrastructure/cached_query.rs:            deduplication.remove(&query_key_clone);
./backend/src/infrastructure/cached_query.rs:    ($cache_manager:expr, $key:expr, $dependencies:expr, $query:block) => {
./backend/src/infrastructure/cached_query.rs:        $cache_manager.execute_cached_query($key, $dependencies, || async move $query).await
./backend/src/infrastructure/cached_query.rs:    ($cache_manager:expr, $query_key:expr, $query:block) => {
./backend/src/infrastructure/cached_query.rs:        $cache_manager.execute_deduplicated_query($query_key, || async move $query).await
./backend/src/infrastructure/cached_query.rs:        let result1 = cached_query!(cache_manager, key.clone(), dependencies.clone(), {
./backend/src/infrastructure/cached_query.rs:        let result2 = cached_query!(cache_manager, key, dependencies, {
./backend/src/infrastructure/cached_query.rs:        let _ = cached_query!(cache_manager, key.clone(), dependencies.clone(), {
./backend/src/infrastructure/cached_query.rs:        // Invalidate the key
./backend/src/infrastructure/cached_query.rs:        cache_manager.invalidate_key(&key).await;
./backend/src/infrastructure/cached_query.rs:        let result = cached_query!(cache_manager, key, dependencies, {
./backend/src/infrastructure/cache_warming.rs:    pub key: CacheKey,
./backend/src/infrastructure/cache_warming.rs:    pub related_keys: Vec<CacheKey>,
./backend/src/infrastructure/cache_warming.rs:    startup_keys: Vec<CacheKey>,
./backend/src/infrastructure/cache_warming.rs:    pub total_keys: usize,
./backend/src/infrastructure/cache_warming.rs:    pub warmed_keys: usize,
./backend/src/infrastructure/cache_warming.rs:    pub failed_keys: usize,
./backend/src/infrastructure/cache_warming.rs:    pub key: CacheKey,
./backend/src/infrastructure/cache_warming.rs:                startup_keys: Vec::new(),
./backend/src/infrastructure/cache_warming.rs:    /// Record access pattern for a cache key
./backend/src/infrastructure/cache_warming.rs:    pub async fn record_access(&self, key: &CacheKey, context: Option<HashMap<String, String>>) {
./backend/src/infrastructure/cache_warming.rs:            .entry(key.clone())
./backend/src/infrastructure/cache_warming.rs:                key: key.clone(),
./backend/src/infrastructure/cache_warming.rs:                related_keys: Vec::new(),
./backend/src/infrastructure/cache_warming.rs:            candidates.insert(key.clone());
./backend/src/infrastructure/cache_warming.rs:            self.trigger_prefetching(key, context.unwrap_or_default())
./backend/src/infrastructure/cache_warming.rs:        for key in candidates {
./backend/src/infrastructure/cache_warming.rs:            match self.warm_key(&key).await {
./backend/src/infrastructure/cache_warming.rs:                    warn!("Failed to warm cache key {}: {}", key, e);
./backend/src/infrastructure/cache_warming.rs:        info!("Cache warming completed, warmed {} keys", warmed_count);
./backend/src/infrastructure/cache_warming.rs:            match self.prefetch_key(&item.key, item.context).await {
./backend/src/infrastructure/cache_warming.rs:                    warn!("Failed to prefetch cache key {}: {}", item.key, e);
./backend/src/infrastructure/cache_warming.rs:    pub async fn add_warming_candidate(&self, key: CacheKey) {
./backend/src/infrastructure/cache_warming.rs:        candidates.insert(key);
./backend/src/infrastructure/cache_warming.rs:    /// Configure startup warming keys
./backend/src/infrastructure/cache_warming.rs:        keys: Vec<CacheKey>,
./backend/src/infrastructure/cache_warming.rs:        startup_data.startup_keys = keys;
./backend/src/infrastructure/cache_warming.rs:        if startup_data.startup_keys.is_empty() {
./backend/src/infrastructure/cache_warming.rs:            "Starting startup cache warming for {} keys",
./backend/src/infrastructure/cache_warming.rs:            startup_data.startup_keys.len()
./backend/src/infrastructure/cache_warming.rs:            total_keys: startup_data.startup_keys.len(),
./backend/src/infrastructure/cache_warming.rs:            warmed_keys: 0,
./backend/src/infrastructure/cache_warming.rs:            failed_keys: 0,
./backend/src/infrastructure/cache_warming.rs:        // Group keys by priority
./backend/src/infrastructure/cache_warming.rs:        let mut keys_by_priority: HashMap<WarmingPriority, Vec<CacheKey>> = HashMap::new();
./backend/src/infrastructure/cache_warming.rs:        for key in &startup_data.startup_keys {
./backend/src/infrastructure/cache_warming.rs:            let priority = self.determine_key_priority(key).await;
./backend/src/infrastructure/cache_warming.rs:            keys_by_priority
./backend/src/infrastructure/cache_warming.rs:                .push(key.clone());
./backend/src/infrastructure/cache_warming.rs:        // Warm keys in priority order
./backend/src/infrastructure/cache_warming.rs:            if let Some(keys) = keys_by_priority.get(priority) {
./backend/src/infrastructure/cache_warming.rs:                info!("Warming {} keys with {:?} priority", keys.len(), priority);
./backend/src/infrastructure/cache_warming.rs:                for key in keys {
./backend/src/infrastructure/cache_warming.rs:                    match self.warm_key_with_fetcher(key, fetcher.clone()).await {
./backend/src/infrastructure/cache_warming.rs:                            progress.warmed_keys += 1;
./backend/src/infrastructure/cache_warming.rs:                            progress.failed_keys += 1;
./backend/src/infrastructure/cache_warming.rs:                            warn!("Failed to warm startup key {}: {}", key, e);
./backend/src/infrastructure/cache_warming.rs:            progress.warmed_keys, progress.failed_keys
./backend/src/infrastructure/cache_warming.rs:    /// Determine priority for a cache key
./backend/src/infrastructure/cache_warming.rs:    async fn determine_key_priority(&self, key: &CacheKey) -> WarmingPriority {
./backend/src/infrastructure/cache_warming.rs:        if let Some(pattern) = patterns.get(key) {
./backend/src/infrastructure/cache_warming.rs:    /// Warm key with custom fetcher
./backend/src/infrastructure/cache_warming.rs:    async fn warm_key_with_fetcher<F, Fut>(&self, key: &CacheKey, fetcher: F) -> HiveResult<()>
./backend/src/infrastructure/cache_warming.rs:            .get_cached::<serde_json::Value>(key)
./backend/src/infrastructure/cache_warming.rs:        let data = fetcher(key.clone()).await?;
./backend/src/infrastructure/cache_warming.rs:        let dependencies = vec![]; // Could be determined based on key relationships
./backend/src/infrastructure/cache_warming.rs:            .set_cached(key.clone(), cache_entry)
./backend/src/infrastructure/cache_warming.rs:        debug!("Successfully warmed cache key: {}", key);
./backend/src/infrastructure/cache_warming.rs:                    key: CacheKey::Custom(recommendation.key.clone()),
./backend/src/infrastructure/cache_warming.rs:                "startup_keys_count": startup_data.startup_keys.len(),
./backend/src/infrastructure/cache_warming.rs:    pub async fn remove_warming_candidate(&self, key: &CacheKey) {
./backend/src/infrastructure/cache_warming.rs:        candidates.remove(key);
./backend/src/infrastructure/cache_warming.rs:        // Find top accessed keys
./backend/src/infrastructure/cache_warming.rs:        let top_keys = top_patterns
./backend/src/infrastructure/cache_warming.rs:                    "key": p.key.to_string(),
./backend/src/infrastructure/cache_warming.rs:            "top_accessed_keys": top_keys,
./backend/src/infrastructure/cache_warming.rs:    async fn warm_key(&self, key: &CacheKey) -> HiveResult<()> {
./backend/src/infrastructure/cache_warming.rs:            .get_cached::<serde_json::Value>(key)
./backend/src/infrastructure/cache_warming.rs:        debug!("Would warm cache key: {}", key);
./backend/src/infrastructure/cache_warming.rs:        candidates.remove(key);
./backend/src/infrastructure/cache_warming.rs:    async fn prefetch_key(
./backend/src/infrastructure/cache_warming.rs:        key: &CacheKey,
./backend/src/infrastructure/cache_warming.rs:        // Similar to warm_key, we can't actually prefetch without fetchers
./backend/src/infrastructure/cache_warming.rs:            "Would prefetch cache key: {} with context {:?}",
./backend/src/infrastructure/cache_warming.rs:            key, context
./backend/src/infrastructure/cache_warming.rs:    async fn trigger_prefetching(&self, key: &CacheKey, context: HashMap<String, String>) {
./backend/src/infrastructure/cache_warming.rs:        if let Some(pattern) = patterns.get(key) {
./backend/src/infrastructure/cache_warming.rs:                        key: key.clone(),
./backend/src/infrastructure/cache_warming.rs:            // Find keys with high access frequency
./backend/src/infrastructure/cache_warming.rs:            let mut high_frequency_keys: Vec<_> = patterns
./backend/src/infrastructure/cache_warming.rs:                .map(|p| p.key.clone())
./backend/src/infrastructure/cache_warming.rs:            high_frequency_keys.sort_by(|a, b| {
./backend/src/infrastructure/cache_warming.rs:            Ok(high_frequency_keys.into_iter().take(50).collect())
./backend/src/infrastructure/cache_warming.rs:        /// Predict keys that will be accessed soon
./backend/src/infrastructure/cache_warming.rs:            let mut predicted_keys: Vec<_> = patterns
./backend/src/infrastructure/cache_warming.rs:                .map(|p| p.key.clone())
./backend/src/infrastructure/cache_warming.rs:            predicted_keys.sort_by(|a, b| {
./backend/src/infrastructure/cache_warming.rs:            Ok(predicted_keys)
./backend/src/infrastructure/cache_warming.rs:        engine.record_access(&key1, None).await;
./backend/src/infrastructure/cache_warming.rs:        engine.record_access(&key2, None).await;
./backend/src/infrastructure/cache_warming.rs:        assert!(patterns.contains_key(&key1));
./backend/src/infrastructure/cache_warming.rs:        assert!(patterns.contains_key(&key2));
./backend/src/infrastructure/security_middleware.rs:            if let Some(token) = auth_str.strip_prefix("Bearer ") {
./backend/src/infrastructure/security_middleware.rs:                match auth_manager.validate_token(token).await {
./backend/src/infrastructure/security_middleware.rs:    // Try API key authentication
./backend/src/infrastructure/security_middleware.rs:    if let Some(api_key_header) = headers.get("x-api-key") {
./backend/src/infrastructure/security_middleware.rs:        if let Ok(api_key) = api_key_header.to_str() {
./backend/src/infrastructure/security_middleware.rs:            match auth_manager.validate_api_key(api_key).await {
./backend/src/infrastructure/security_middleware.rs:                    // Check if API key has required permission
./backend/src/infrastructure/security_middleware.rs:                            // Create pseudo-claims for API key
./backend/src/infrastructure/security_middleware.rs:                                sub: "api_key".to_string(),
./backend/src/infrastructure/security_middleware.rs:                                session_id: "api_key_session".to_string(),
./backend/src/infrastructure/security_middleware.rs:                    // API key is valid and no specific permission required
./backend/src/infrastructure/security_middleware.rs:                        sub: "api_key".to_string(),
./backend/src/infrastructure/security_middleware.rs:                        session_id: "api_key_session".to_string(),
./backend/src/infrastructure/cpu_optimizer.rs:                    .min_by_key(|(_, w)| w.active_tasks)
./backend/src/infrastructure/cache_invalidation.rs:    /// Pattern to match cache keys (supports regex)
./backend/src/infrastructure/cache_invalidation.rs:    pub key_pattern: String,
./backend/src/infrastructure/cache_invalidation.rs:    /// Forward dependencies: key -> dependent keys
./backend/src/infrastructure/cache_invalidation.rs:    /// Reverse dependencies: key -> keys that depend on it
./backend/src/infrastructure/cache_invalidation.rs:    pub fn add_dependency(&mut self, key: CacheKey, depends_on: CacheKey) {
./backend/src/infrastructure/cache_invalidation.rs:        // Forward: key depends on depends_on
./backend/src/infrastructure/cache_invalidation.rs:            .entry(key.clone())
./backend/src/infrastructure/cache_invalidation.rs:        // Reverse: depends_on is depended on by key
./backend/src/infrastructure/cache_invalidation.rs:            .insert(key);
./backend/src/infrastructure/cache_invalidation.rs:    pub fn remove_dependency(&mut self, key: &CacheKey, depends_on: &CacheKey) {
./backend/src/infrastructure/cache_invalidation.rs:        if let Some(deps) = self.forward_deps.get_mut(key) {
./backend/src/infrastructure/cache_invalidation.rs:            rev_deps.remove(key);
./backend/src/infrastructure/cache_invalidation.rs:    /// Get all keys that depend on the given key
./backend/src/infrastructure/cache_invalidation.rs:    pub fn get_dependents(&self, key: &CacheKey) -> HashSet<CacheKey> {
./backend/src/infrastructure/cache_invalidation.rs:        self.reverse_deps.get(key).cloned().unwrap_or_default()
./backend/src/infrastructure/cache_invalidation.rs:    /// Get all keys that the given key depends on
./backend/src/infrastructure/cache_invalidation.rs:    pub fn get_dependencies(&self, key: &CacheKey) -> HashSet<CacheKey> {
./backend/src/infrastructure/cache_invalidation.rs:        self.forward_deps.get(key).cloned().unwrap_or_default()
./backend/src/infrastructure/cache_invalidation.rs:    /// Last invalidation times for keys
./backend/src/infrastructure/cache_invalidation.rs:    /// Invalidate a single cache key
./backend/src/infrastructure/cache_invalidation.rs:    pub async fn invalidate_key(&self, key: &CacheKey) -> HiveResult<()> {
./backend/src/infrastructure/cache_invalidation.rs:        debug!("Invalidating cache key: {}", key);
./backend/src/infrastructure/cache_invalidation.rs:        // Invalidate the key itself
./backend/src/infrastructure/cache_invalidation.rs:        self.cache_manager.invalidate_key(key).await;
./backend/src/infrastructure/cache_invalidation.rs:        self.handle_cascade_invalidation(key).await?;
./backend/src/infrastructure/cache_invalidation.rs:    /// Invalidate multiple keys with batching
./backend/src/infrastructure/cache_invalidation.rs:    pub async fn invalidate_keys(&self, keys: &[CacheKey]) -> HiveResult<()> {
./backend/src/infrastructure/cache_invalidation.rs:                self.invalidate_keys_batched(keys, *batch_size).await
./backend/src/infrastructure/cache_invalidation.rs:                for key in keys {
./backend/src/infrastructure/cache_invalidation.rs:                    self.invalidate_key(key).await?;
./backend/src/infrastructure/cache_invalidation.rs:    /// Invalidate keys based on a pattern
./backend/src/infrastructure/cache_invalidation.rs:        // For now, just invalidate keys that contain the pattern
./backend/src/infrastructure/cache_invalidation.rs:        let keys_to_check: Vec<CacheKey> = {
./backend/src/infrastructure/cache_invalidation.rs:        for key in keys_to_check {
./backend/src/infrastructure/cache_invalidation.rs:            if key.to_string().contains(pattern) {
./backend/src/infrastructure/cache_invalidation.rs:                self.invalidate_key(&key).await?;
./backend/src/infrastructure/cache_invalidation.rs:            "Invalidated {} keys matching pattern: {}",
./backend/src/infrastructure/cache_invalidation.rs:    pub async fn add_dependency(&self, key: CacheKey, depends_on: CacheKey) {
./backend/src/infrastructure/cache_invalidation.rs:        graph.add_dependency(key, depends_on);
./backend/src/infrastructure/cache_invalidation.rs:    pub async fn remove_dependency(&self, key: &CacheKey, depends_on: &CacheKey) {
./backend/src/infrastructure/cache_invalidation.rs:        graph.remove_dependency(key, depends_on);
./backend/src/infrastructure/cache_invalidation.rs:        // Invalidate keys that exceed threshold in current window
./backend/src/infrastructure/cache_invalidation.rs:        let keys_to_check: Vec<CacheKey> = state.invalidation_counts.keys().cloned().collect();
./backend/src/infrastructure/cache_invalidation.rs:        for key in keys_to_check {
./backend/src/infrastructure/cache_invalidation.rs:            if let Some(counts) = state.invalidation_counts.get(&key) {
./backend/src/infrastructure/cache_invalidation.rs:                    self.invalidate_key(&key).await?;
./backend/src/infrastructure/cache_invalidation.rs:                    // Reset the window for this key
./backend/src/infrastructure/cache_invalidation.rs:                    state.invalidation_counts.remove(&key);
./backend/src/infrastructure/cache_invalidation.rs:                    state.last_invalidation_times.insert(key, now);
./backend/src/infrastructure/cache_invalidation.rs:        // Get all cache keys (this would need to be implemented in the cache manager)
./backend/src/infrastructure/cache_invalidation.rs:        let all_keys: Vec<CacheKey> = vec![]; // Placeholder - would need cache manager method
./backend/src/infrastructure/cache_invalidation.rs:        for key in all_keys {
./backend/src/infrastructure/cache_invalidation.rs:            let age = if let Some(last_invalidation) = state.age_distribution.get(&key) {
./backend/src/infrastructure/cache_invalidation.rs:                self.invalidate_key(&key).await?;
./backend/src/infrastructure/cache_invalidation.rs:                state.age_distribution.insert(key, Duration::from_secs(0));
./backend/src/infrastructure/cache_invalidation.rs:        // Get all cache keys (this would need to be implemented in the cache manager)
./backend/src/infrastructure/cache_invalidation.rs:        let all_keys: Vec<CacheKey> = vec![]; // Placeholder - would need cache manager method
./backend/src/infrastructure/cache_invalidation.rs:        for key in all_keys {
./backend/src/infrastructure/cache_invalidation.rs:            if regex.is_match(&key.to_string()) {
./backend/src/infrastructure/cache_invalidation.rs:                self.invalidate_key(&key).await?;
./backend/src/infrastructure/cache_invalidation.rs:            "Invalidated {} keys matching regex pattern: {}",
./backend/src/infrastructure/cache_invalidation.rs:    pub async fn invalidate_by_access_pattern(&self, key: &CacheKey) -> HiveResult<bool> {
./backend/src/infrastructure/cache_invalidation.rs:            // Check if key matches the pattern
./backend/src/infrastructure/cache_invalidation.rs:            if key.to_string().contains(&rule.base_rule.key_pattern) {
./backend/src/infrastructure/cache_invalidation.rs:                        self.check_access_pattern_condition(key, condition).await;
./backend/src/infrastructure/cache_invalidation.rs:                        self.invalidate_key(key).await?;
./backend/src/infrastructure/cache_invalidation.rs:        key: &CacheKey,
./backend/src/infrastructure/cache_invalidation.rs:        for (key, size) in cache_sizes {
./backend/src/infrastructure/cache_invalidation.rs:                self.invalidate_key(&key).await?;
./backend/src/infrastructure/cache_invalidation.rs:            "Invalidated {} keys exceeding size threshold: {} bytes",
./backend/src/infrastructure/cache_invalidation.rs:            key_pattern: "temp_*".to_string(),
./backend/src/infrastructure/cache_invalidation.rs:            key_pattern: "stale_*".to_string(),
./backend/src/infrastructure/cache_invalidation.rs:                .invalidate_by_pattern(&recommendation.key_pattern)
./backend/src/infrastructure/cache_invalidation.rs:                "Applied recommendation: {} - invalidated {} keys",
./backend/src/infrastructure/cache_invalidation.rs:            let keys = pending_invalidations.drain().collect();
./backend/src/infrastructure/cache_invalidation.rs:            keys
./backend/src/infrastructure/cache_invalidation.rs:            for key in &pending {
./backend/src/infrastructure/cache_invalidation.rs:                self.invalidate_key(key).await?;
./backend/src/infrastructure/cache_invalidation.rs:    async fn handle_cascade_invalidation(&self, key: &CacheKey) -> HiveResult<()> {
./backend/src/infrastructure/cache_invalidation.rs:        let dependents = graph.get_dependents(key);
./backend/src/infrastructure/cache_invalidation.rs:                "Invalidating {} dependent keys for: {}",
./backend/src/infrastructure/cache_invalidation.rs:                dependents_count, key
./backend/src/infrastructure/cache_invalidation.rs:                self.cache_manager.invalidate_key(dependent).await;
./backend/src/infrastructure/cache_invalidation.rs:    /// Invalidate keys in batches
./backend/src/infrastructure/cache_invalidation.rs:    async fn invalidate_keys_batched(
./backend/src/infrastructure/cache_invalidation.rs:        keys: &[CacheKey],
./backend/src/infrastructure/cache_invalidation.rs:        for chunk in keys.chunks(batch_size) {
./backend/src/infrastructure/cache_invalidation.rs:            for key in chunk {
./backend/src/infrastructure/cache_invalidation.rs:                pending.insert(key.clone());
./backend/src/infrastructure/cache_invalidation.rs:    /// Check if a key should be invalidated based on rules
./backend/src/infrastructure/cache_invalidation.rs:    pub async fn should_invalidate(&self, key: &CacheKey) -> bool {
./backend/src/infrastructure/cache_invalidation.rs:            if key.to_string().contains(&rule.key_pattern) {
./backend/src/infrastructure/cache_invalidation.rs:                    if key.to_string().contains(dep_pattern) {
./backend/src/infrastructure/cache_invalidation.rs:    pub async fn get_dependency_info(&self, key: &CacheKey) -> DependencyInfo {
./backend/src/infrastructure/cache_invalidation.rs:            key: key.clone(),
./backend/src/infrastructure/cache_invalidation.rs:            depends_on: graph.get_dependencies(key).into_iter().collect(),
./backend/src/infrastructure/cache_invalidation.rs:            depended_by: graph.get_dependents(key).into_iter().collect(),
./backend/src/infrastructure/cache_invalidation.rs:/// Dependency information for a cache key
./backend/src/infrastructure/cache_invalidation.rs:    pub key: CacheKey,
./backend/src/infrastructure/cache_invalidation.rs:    pub key_pattern: String,
./backend/src/infrastructure/cache_invalidation.rs:        let keys = vec![CacheKey::Agent(agent_id), CacheKey::AgentMetrics(agent_id)];
./backend/src/infrastructure/cache_invalidation.rs:        self.base_manager.invalidate_keys(&keys).await?;
./backend/src/infrastructure/cache_invalidation.rs:        // This would need to be implemented to get all agent keys
./backend/src/infrastructure/cache_invalidation.rs:                key_pattern: "agent".to_string(),
./backend/src/infrastructure/cache_invalidation.rs:                key_pattern: "agent_metrics".to_string(),
./backend/src/infrastructure/cache_invalidation.rs:        let keys = vec![CacheKey::Task(task_id), CacheKey::TaskMetrics(task_id)];
./backend/src/infrastructure/cache_invalidation.rs:        self.base_manager.invalidate_keys(&keys).await?;
./backend/src/infrastructure/cache_invalidation.rs:        let keys = vec![
./backend/src/infrastructure/cache_invalidation.rs:        self.base_manager.invalidate_keys(&keys).await?;
./backend/src/infrastructure/cache_invalidation.rs:                key_pattern: "task".to_string(),
./backend/src/infrastructure/cache_invalidation.rs:                key_pattern: "task_metrics".to_string(),
./backend/src/infrastructure/cache_invalidation.rs:        let key1 = CacheKey::Agent(Uuid::new_v4());
./backend/src/infrastructure/cache_invalidation.rs:        let key2 = CacheKey::Task(Uuid::new_v4());
./backend/src/infrastructure/cache_invalidation.rs:        let key3 = CacheKey::AgentMetrics(Uuid::new_v4());
./backend/src/infrastructure/cache_invalidation.rs:        // key1 depends on key2
./backend/src/infrastructure/cache_invalidation.rs:        graph.add_dependency(key1.clone(), key2.clone());
./backend/src/infrastructure/cache_invalidation.rs:        // key3 depends on key1
./backend/src/infrastructure/cache_invalidation.rs:        graph.add_dependency(key3.clone(), key1.clone());
./backend/src/infrastructure/cache_invalidation.rs:        assert!(graph.get_dependencies(&key1).contains(&key2));
./backend/src/infrastructure/cache_invalidation.rs:        assert!(graph.get_dependents(&key1).contains(&key3));
./backend/src/infrastructure/cache_invalidation.rs:        assert!(graph.get_dependents(&key2).contains(&key1));
./backend/src/infrastructure/cache_invalidation.rs:        let dep_key = CacheKey::Custom("dep_key".to_string());
./backend/src/infrastructure/cache_invalidation.rs:            .add_dependency(key.clone(), dep_key.clone())
./backend/src/infrastructure/cache_invalidation.rs:        invalidation_manager.invalidate_key(&dep_key).await?;
./backend/src/infrastructure/cache_invalidation.rs:        // Check that dependent key was also invalidated
./backend/src/infrastructure/connection_pool.rs:    pub async fn get(&self, key: &str) -> Option<CachedResponse> {
./backend/src/infrastructure/connection_pool.rs:        if let Some(response) = cache.get(key) {
./backend/src/infrastructure/connection_pool.rs:                cache.remove(key);
./backend/src/infrastructure/connection_pool.rs:    pub async fn set(&self, key: String, data: Vec<u8>, content_type: String) {
./backend/src/infrastructure/connection_pool.rs:            if let Some(oldest_key) = cache.keys().next().cloned() {
./backend/src/infrastructure/connection_pool.rs:                cache.remove(&oldest_key);
./backend/src/infrastructure/connection_pool.rs:        cache.insert(key, response);
./backend/src/infrastructure/connection_pool.rs:        cache.set(key.clone(), data.clone(), content_type.clone()).await;
./backend/src/infrastructure/connection_pool.rs:        let cached = cache.get(&key).await
./backend/src/infrastructure/throughput_optimizer.rs:    pub async fn cache_data(&self, key: String, data: Vec<u8>) -> HiveResult<()> {
./backend/src/infrastructure/throughput_optimizer.rs:        self.intelligent_cache.set(key, data).await
./backend/src/infrastructure/throughput_optimizer.rs:    pub async fn get_cached_data(&self, key: &str) -> Option<Vec<u8>> {
./backend/src/infrastructure/throughput_optimizer.rs:        self.intelligent_cache.get(key).await
./backend/src/infrastructure/performance_optimizer.rs:    pub async fn get(&self, key: &str) -> Option<Vec<u8>> {
./backend/src/infrastructure/performance_optimizer.rs:        if let Some(entry) = cache.get_mut(key) {
./backend/src/infrastructure/performance_optimizer.rs:            cache.remove(key);
./backend/src/infrastructure/performance_optimizer.rs:    pub async fn put(&self, key: String, data: Vec<u8>) -> HiveResult<()> {
./backend/src/infrastructure/performance_optimizer.rs:        cache.insert(key, entry);
./backend/src/infrastructure/performance_optimizer.rs:        entries.sort_by_key(|(_, entry)| entry.last_accessed);
./backend/src/infrastructure/performance_optimizer.rs:        let mut keys_to_remove = Vec::new();
./backend/src/infrastructure/performance_optimizer.rs:        for (key, entry) in entries {
./backend/src/infrastructure/performance_optimizer.rs:            keys_to_remove.push(key.clone());
./backend/src/infrastructure/performance_optimizer.rs:        for key in keys_to_remove {
./backend/src/infrastructure/performance_optimizer.rs:            cache.remove(&key);
./backend/src/infrastructure/performance_optimizer.rs:        let mut keys_to_remove = Vec::new();
./backend/src/infrastructure/performance_optimizer.rs:        for (key, entry) in cache_guard.iter() {
./backend/src/infrastructure/performance_optimizer.rs:                keys_to_remove.push(key.clone());
./backend/src/infrastructure/performance_optimizer.rs:        for key in keys_to_remove {
./backend/src/infrastructure/performance_optimizer.rs:            cache_guard.remove(&key);
./backend/src/infrastructure/performance_optimizer.rs:        assert!(cache.get(&key).await.is_none());
./backend/src/infrastructure/performance_optimizer.rs:        match cache.put(key.clone(), data.clone()).await {
./backend/src/infrastructure/performance_optimizer.rs:        let Some(cached_data) = cache.get(&key).await else {
./backend/src/infrastructure/cache.rs:    pub async fn insert(&self, key: K, value: V) {
./backend/src/infrastructure/cache.rs:        self.insert_with_ttl(key, value, self.default_ttl).await;
./backend/src/infrastructure/cache.rs:    pub async fn insert_with_ttl(&self, key: K, value: V, ttl: Duration) {
./backend/src/infrastructure/cache.rs:        let size_bytes = self.calculate_entry_size(&key, &value);
./backend/src/infrastructure/cache.rs:        data.insert(key, entry);
./backend/src/infrastructure/cache.rs:    pub async fn get(&self, key: &K) -> Option<V> {
./backend/src/infrastructure/cache.rs:        if let Some(entry) = data.get_mut(key) {
./backend/src/infrastructure/cache.rs:                data.remove(key);
./backend/src/infrastructure/cache.rs:    pub async fn remove(&self, key: &K) -> Option<V> {
./backend/src/infrastructure/cache.rs:        data.remove(key).map(|entry| entry.value)
./backend/src/infrastructure/cache.rs:            if let Some((key, entry)) = eviction_candidate {
./backend/src/infrastructure/cache.rs:                entries_to_evict.push((key, entry.size_bytes));
./backend/src/infrastructure/cache.rs:        for (key, size) in entries_to_evict {
./backend/src/infrastructure/cache.rs:            if let Some(entry) = data.remove(&key) {
./backend/src/infrastructure/cache.rs:                .min_by_key(|(_, entry)| entry.last_accessed)
./backend/src/infrastructure/cache.rs:                .min_by_key(|(_, entry)| entry.access_count)
./backend/src/infrastructure/cache.rs:                    .min_by_key(|(_, entry)| {
./backend/src/infrastructure/cache.rs:    fn calculate_entry_size(&self, key: &K, value: &V) -> usize {
./backend/src/infrastructure/cache.rs:        let key_size = std::mem::size_of_val(key);
./backend/src/infrastructure/cache.rs:        key_size + value_size + 128 // Overhead for HashMap entry
./backend/src/infrastructure/telemetry.rs:            let type_key = format!("{event_type:?}");
./backend/src/infrastructure/telemetry.rs:            *metrics.events_by_type.entry(type_key).or_insert(0) += 1;
./backend/src/infrastructure/telemetry.rs:            let severity_key = format!("{severity:?}");
./backend/src/infrastructure/telemetry.rs:            *metrics.events_by_severity.entry(severity_key).or_insert(0) += 1;
./backend/src/infrastructure/telemetry.rs:    ($collector:expr, $source:expr, $($key:expr => $value:expr),*) => {
./backend/src/infrastructure/telemetry.rs:            serde_json::json!({ $($key: $value),* }),
./backend/src/infrastructure/monitoring_legacy.rs:    pub key_findings: Vec<String>,
./backend/src/infrastructure/monitoring_legacy.rs:                    let _active_agents: Vec<Uuid> = health_map.keys().copied().collect();
./backend/src/infrastructure/monitoring_legacy.rs:                // Generate trend data for key metrics
./backend/src/infrastructure/monitoring_legacy.rs:            let latency_key = format!("MONITORING_{}_LATENCY", component.to_uppercase());
./backend/src/infrastructure/monitoring_legacy.rs:            let latency = std::env::var(&latency_key)
./backend/src/infrastructure/monitoring_legacy.rs:            let throughput_key = format!("MONITORING_{}_THROUGHPUT", component.to_uppercase());
./backend/src/infrastructure/monitoring_legacy.rs:            let throughput = std::env::var(&throughput_key)
./backend/src/infrastructure/monitoring_legacy.rs:            key_findings: vec![
./backend/src/infrastructure/monitoring_legacy.rs:            key_findings: vec![
./backend/src/infrastructure/monitoring_legacy.rs:            key_findings: vec![
./backend/src/infrastructure/monitoring_legacy.rs:            key_findings: vec![
./backend/src/infrastructure/monitoring_legacy.rs:    pub async fn setup_grafana_integration(&self, endpoint: &str, api_key: &str) -> HiveResult<()> {
./backend/src/infrastructure/monitoring_legacy.rs:                config.insert("api_key".to_string(), api_key.to_string());
./backend/src/infrastructure/monitoring_legacy.rs:        password: &str,
./backend/src/infrastructure/monitoring_legacy.rs:                config.insert("password".to_string(), password.to_string());
./backend/src/infrastructure/persistence.rs:    pub encryption_key: Option<String>,
./backend/src/infrastructure/persistence.rs:    encryption_key: Option<[u8; 32]>,
./backend/src/infrastructure/persistence.rs:    /// Load encryption key from environment or secure storage
./backend/src/infrastructure/persistence.rs:    pub fn load_encryption_key() -> Option<String> {
./backend/src/infrastructure/persistence.rs:        std::env::var("HIVE_ENCRYPTION_KEY").ok()
./backend/src/infrastructure/persistence.rs:        let encryption_key = config.encryption_key.as_ref().map(|s| {
./backend/src/infrastructure/persistence.rs:            let mut key = [0u8; 32];
./backend/src/infrastructure/persistence.rs:            key[..len].copy_from_slice(&bytes[..len]);
./backend/src/infrastructure/persistence.rs:            key
./backend/src/infrastructure/persistence.rs:            encryption_key,
./backend/src/infrastructure/persistence.rs:                id TEXT PRIMARY KEY,
./backend/src/infrastructure/persistence.rs:            let oldest_key = snapshots.keys().next().cloned();
./backend/src/infrastructure/persistence.rs:            if let Some(key) = oldest_key {
./backend/src/infrastructure/persistence.rs:                snapshots.remove(&key);
./backend/src/infrastructure/persistence.rs:            let oldest_key = snapshots.keys().next().cloned();
./backend/src/infrastructure/persistence.rs:            if let Some(key) = oldest_key {
./backend/src/infrastructure/persistence.rs:                snapshots.remove(&key);
./backend/src/infrastructure/persistence.rs:        let keys_to_remove: Vec<String> = snapshots.keys().take(to_remove).cloned().collect();
./backend/src/infrastructure/persistence.rs:        for key in &keys_to_remove {
./backend/src/infrastructure/persistence.rs:            snapshots.remove(key);
./backend/src/infrastructure/persistence.rs:        Ok(keys_to_remove.len())
./backend/src/infrastructure/persistence.rs:            encryption_key: None,
./backend/src/infrastructure/intelligent_cache.rs:    pub query_key: String,
./backend/src/infrastructure/intelligent_cache.rs:    pub query_key: String,
./backend/src/infrastructure/intelligent_cache.rs:    /// Classify based on key patterns
./backend/src/infrastructure/intelligent_cache.rs:    /// Sequential access patterns (what comes after this key)
./backend/src/infrastructure/intelligent_cache.rs:    fn record_access(&mut self, previous_key: Option<&str>) {
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(prev_key) = previous_key {
./backend/src/infrastructure/intelligent_cache.rs:                .entry(prev_key.to_string())
./backend/src/infrastructure/intelligent_cache.rs:    /// Check if this key is in a burst access pattern
./backend/src/infrastructure/intelligent_cache.rs:            .map(|(key, count)| (key.clone(), *count as f64 / total_sequential as f64))
./backend/src/infrastructure/intelligent_cache.rs:    last_accessed_key: Arc<RwLock<Option<K>>>,
./backend/src/infrastructure/intelligent_cache.rs:            last_accessed_key: Arc::new(RwLock::new(None)),
./backend/src/infrastructure/intelligent_cache.rs:    pub async fn get(&self, key: &K) -> Option<V> {
./backend/src/infrastructure/intelligent_cache.rs:        // Get the previous key for sequential pattern tracking
./backend/src/infrastructure/intelligent_cache.rs:        let previous_key = {
./backend/src/infrastructure/intelligent_cache.rs:            let mut last_key = self.last_accessed_key.write().await;
./backend/src/infrastructure/intelligent_cache.rs:            let prev = last_key.clone();
./backend/src/infrastructure/intelligent_cache.rs:            *last_key = Some(key.clone());
./backend/src/infrastructure/intelligent_cache.rs:        self.record_access(key, previous_key.as_ref()).await;
./backend/src/infrastructure/intelligent_cache.rs:        let result = self.cache.get(key).await;
./backend/src/infrastructure/intelligent_cache.rs:                if prefetch_queue.contains(&key.to_string()) {
./backend/src/infrastructure/intelligent_cache.rs:    pub async fn set(&self, key: K, value: V) -> HiveResult<()> {
./backend/src/infrastructure/intelligent_cache.rs:            self.calculate_adaptive_ttl(&key).await
./backend/src/infrastructure/intelligent_cache.rs:        self.cache.insert_with_ttl(key.clone(), value, ttl).await;
./backend/src/infrastructure/intelligent_cache.rs:    pub async fn set_with_ttl(&self, key: K, value: V, ttl: Duration) -> HiveResult<()> {
./backend/src/infrastructure/intelligent_cache.rs:        self.cache.insert_with_ttl(key, value, ttl).await;
./backend/src/infrastructure/intelligent_cache.rs:    pub async fn remove(&self, key: &K) -> Option<V> {
./backend/src/infrastructure/intelligent_cache.rs:            patterns.remove(key);
./backend/src/infrastructure/intelligent_cache.rs:        self.cache.remove(key).await
./backend/src/infrastructure/intelligent_cache.rs:    pub async fn prefetch<F, Fut>(&self, key: K, loader: F) -> HiveResult<()>
./backend/src/infrastructure/intelligent_cache.rs:        if self.cache.get(&key).await.is_some() {
./backend/src/infrastructure/intelligent_cache.rs:                self.set(key.clone(), value).await?;
./backend/src/infrastructure/intelligent_cache.rs:                    queue.push_back(key.to_string());
./backend/src/infrastructure/intelligent_cache.rs:                debug!("Successfully prefetched data for key");
./backend/src/infrastructure/intelligent_cache.rs:    /// Record access pattern for a key
./backend/src/infrastructure/intelligent_cache.rs:    async fn record_access(&self, key: &K, previous_key: Option<&K>) {
./backend/src/infrastructure/intelligent_cache.rs:            .entry(key.clone())
./backend/src/infrastructure/intelligent_cache.rs:        pattern.record_access(previous_key.map(|k| k.as_ref()));
./backend/src/infrastructure/intelligent_cache.rs:            self.trigger_predictive_prefetching(key).await;
./backend/src/infrastructure/intelligent_cache.rs:    async fn trigger_predictive_prefetching(&self, key: &K) {
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(pattern) = patterns.get(key) {
./backend/src/infrastructure/intelligent_cache.rs:            for (next_key, probability) in sequential_predictions.into_iter().take(3) {
./backend/src/infrastructure/intelligent_cache.rs:                        key.to_string(),
./backend/src/infrastructure/intelligent_cache.rs:                        next_key,
./backend/src/infrastructure/intelligent_cache.rs:                    queue.push_back(next_key.clone());
./backend/src/infrastructure/intelligent_cache.rs:                    "Burst access detected for key: {}, triggering aggressive prefetching",
./backend/src/infrastructure/intelligent_cache.rs:                    key.to_string()
./backend/src/infrastructure/intelligent_cache.rs:                self.trigger_burst_prefetching(key).await;
./backend/src/infrastructure/intelligent_cache.rs:    async fn trigger_burst_prefetching(&self, key: &K) {
./backend/src/infrastructure/intelligent_cache.rs:        // Find other keys with similar access patterns
./backend/src/infrastructure/intelligent_cache.rs:        let similar_keys: Vec<String> = patterns
./backend/src/infrastructure/intelligent_cache.rs:                k.as_ref() != key.as_ref() && p.access_frequency > 0.1 && p.is_in_burst()
./backend/src/infrastructure/intelligent_cache.rs:        for similar_key in similar_keys {
./backend/src/infrastructure/intelligent_cache.rs:            debug!("Burst prefetching similar key: {}", similar_key);
./backend/src/infrastructure/intelligent_cache.rs:            queue.push_back(similar_key);
./backend/src/infrastructure/intelligent_cache.rs:    /// Calculate adaptive TTL for a key
./backend/src/infrastructure/intelligent_cache.rs:    async fn calculate_adaptive_ttl(&self, key: &K) -> Duration {
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(pattern) = patterns.get(key) {
./backend/src/infrastructure/intelligent_cache.rs:    /// Get keys that should be prefetched
./backend/src/infrastructure/intelligent_cache.rs:            .map(|(key, _)| key.clone())
./backend/src/infrastructure/intelligent_cache.rs:    /// Get TTL adaptation statistics for all keys
./backend/src/infrastructure/intelligent_cache.rs:            .map(|(key, pattern)| (key.clone(), pattern.get_ttl_stats()))
./backend/src/infrastructure/intelligent_cache.rs:        for (key, pattern) in &*patterns {
./backend/src/infrastructure/intelligent_cache.rs:                key: key.clone(),
./backend/src/infrastructure/intelligent_cache.rs:                sequential_keys: sequential_predictions
./backend/src/infrastructure/intelligent_cache.rs:    /// Calculate predicted benefit of prefetching a key
./backend/src/infrastructure/intelligent_cache.rs:            let key_clone = recommendation.key.clone();
./backend/src/infrastructure/intelligent_cache.rs:                match loader_clone(key_clone).await {
./backend/src/infrastructure/intelligent_cache.rs:            let key_clone = recommendation.key.clone();
./backend/src/infrastructure/intelligent_cache.rs:                match loader_clone(key_clone).await {
./backend/src/infrastructure/intelligent_cache.rs:            let key_clone = recommendation.key.clone();
./backend/src/infrastructure/intelligent_cache.rs:                let _ = loader_clone(key_clone).await;
./backend/src/infrastructure/intelligent_cache.rs:    pub key: String,
./backend/src/infrastructure/intelligent_cache.rs:    pub key: K,
./backend/src/infrastructure/intelligent_cache.rs:    pub sequential_keys: Vec<String>,
./backend/src/infrastructure/intelligent_cache.rs:                let task_id = format!("warm_{}", request.key);
./backend/src/infrastructure/intelligent_cache.rs:                                "Successfully warmed cache for key: {} in {:.4}s",
./backend/src/infrastructure/intelligent_cache.rs:                                request.key,
./backend/src/infrastructure/intelligent_cache.rs:                            tracing::warn!("Failed to warm cache for key: {}: {}", request.key, e);
./backend/src/infrastructure/intelligent_cache.rs:        for (key, records) in &analyzer.patterns {
./backend/src/infrastructure/intelligent_cache.rs:                        recommendations.push(key.clone());
./backend/src/infrastructure/intelligent_cache.rs:    pub fn record_access(&mut self, key: &str, access_type: AccessType) {
./backend/src/infrastructure/intelligent_cache.rs:            frequency_score: self.calculate_frequency_score(key),
./backend/src/infrastructure/intelligent_cache.rs:            .entry(key.to_string())
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(records) = self.patterns.get_mut(key) {
./backend/src/infrastructure/intelligent_cache.rs:        self.update_prediction_model(key);
./backend/src/infrastructure/intelligent_cache.rs:    /// Calculate frequency score for a key
./backend/src/infrastructure/intelligent_cache.rs:    fn calculate_frequency_score(&self, key: &str) -> f64 {
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(records) = self.patterns.get(key) {
./backend/src/infrastructure/intelligent_cache.rs:    /// Update prediction model for a key
./backend/src/infrastructure/intelligent_cache.rs:    fn update_prediction_model(&mut self, key: &str) {
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(records) = self.patterns.get(key) {
./backend/src/infrastructure/intelligent_cache.rs:                self.prediction_model.insert(key.to_string(), model);
./backend/src/infrastructure/intelligent_cache.rs:    /// Predict if key will be accessed soon
./backend/src/infrastructure/intelligent_cache.rs:    pub fn predict_access(&self, key: &str) -> Option<f64> {
./backend/src/infrastructure/intelligent_cache.rs:            .get(key)
./backend/src/infrastructure/intelligent_cache.rs:    pub async fn get(&self, key: &str) -> Option<serde_json::Value> {
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(value) = self.l1_cache.get(&key.to_string()).await {
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(value) = self.l2_cache.get(&key.to_string()).await {
./backend/src/infrastructure/intelligent_cache.rs:            let _ = self.l1_cache.set(key.to_string(), value.clone()).await;
./backend/src/infrastructure/intelligent_cache.rs:    pub async fn set(&self, key: String, value: serde_json::Value) -> HiveResult<()> {
./backend/src/infrastructure/intelligent_cache.rs:        self.l1_cache.set(key.clone(), value.clone()).await?;
./backend/src/infrastructure/intelligent_cache.rs:        self.l2_cache.set(key, value).await?;
./backend/src/infrastructure/intelligent_cache.rs:        let query_key = request.query_key.clone();
./backend/src/infrastructure/intelligent_cache.rs:            .entry(query_key)
./backend/src/infrastructure/intelligent_cache.rs:    pub async fn get_with_warming(&self, key: &str) -> Option<serde_json::Value> {
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(value) = self.l1_cache.get(&key.to_string()).await {
./backend/src/infrastructure/intelligent_cache.rs:            self.record_cache_hit(key).await;
./backend/src/infrastructure/intelligent_cache.rs:        if let Some(value) = self.l2_cache.get(&key.to_string()).await {
./backend/src/infrastructure/intelligent_cache.rs:            let _ = self.l1_cache.set(key.to_string(), value.clone()).await;
./backend/src/infrastructure/intelligent_cache.rs:            self.record_cache_hit(key).await;
./backend/src/infrastructure/intelligent_cache.rs:            self.analyze_and_trigger_warming(key).await;
./backend/src/infrastructure/intelligent_cache.rs:        self.record_cache_miss(key).await;
./backend/src/infrastructure/intelligent_cache.rs:        key: String,
./backend/src/infrastructure/intelligent_cache.rs:        self.l1_cache.set(key.clone(), value.clone()).await?;
./backend/src/infrastructure/intelligent_cache.rs:        self.l2_cache.set(key.clone(), value).await?;
./backend/src/infrastructure/intelligent_cache.rs:        self.analyze_and_trigger_warming(&key).await;
./backend/src/infrastructure/intelligent_cache.rs:    async fn record_cache_hit(&self, key: &str) {
./backend/src/infrastructure/intelligent_cache.rs:        analyzer.record_access(key, AccessType::Read);
./backend/src/infrastructure/intelligent_cache.rs:    async fn record_cache_miss(&self, key: &str) {
./backend/src/infrastructure/intelligent_cache.rs:        analyzer.record_access(key, AccessType::Read);
./backend/src/infrastructure/intelligent_cache.rs:    async fn analyze_and_trigger_warming(&self, key: &str) {
./backend/src/infrastructure/intelligent_cache.rs:        if recommendations.contains(&key.to_string()) {
./backend/src/infrastructure/intelligent_cache.rs:            // Create warming request for this key
./backend/src/infrastructure/intelligent_cache.rs:                key: key.to_string(),
./backend/src/infrastructure/intelligent_cache.rs:            .set("key1".to_string(), serde_json::json!({"value": 42}))
./backend/src/infrastructure/intelligent_cache.rs:        let value = cache_manager.get("key1").await;
./backend/src/infrastructure/intelligent_cache.rs:            .prefetch("prefetch_key".to_string(), || async {
./backend/src/infrastructure/intelligent_cache.rs:        let value = cache.get(&"prefetch_key".to_string()).await;
./backend/src/infrastructure/intelligent_cache.rs:                    "id": key,
./backend/src/infrastructure/intelligent_cache.rs:                    "name": format!("User {}", key),
./backend/src/infrastructure/intelligent_cache.rs:                    "id": key,
./backend/src/infrastructure/intelligent_cache.rs:                    "name": format!("Product {}", key),
./backend/src/infrastructure/intelligent_cache.rs:                    "id": key,
./backend/src/infrastructure/intelligent_cache.rs:                Ok(serde_json::json!({"data": format!("Generic data for {}", key)}))
./backend/src/infrastructure/intelligent_cache.rs:            let cache_key = CacheKey::Custom(format!("{}:{}", query_type, key));
./backend/src/infrastructure/intelligent_cache.rs:                .execute_cached_query(cache_key, vec![], || async {
./backend/src/infrastructure/intelligent_cache.rs:            let cache_key = CacheKey::Custom(format!("{}:{}", query_type, key));
./backend/src/infrastructure/intelligent_cache.rs:                .execute_cached_query(cache_key, vec![], || async {
./backend/src/infrastructure/intelligent_cache.rs:            let query_key_clone = query_key.clone();
./backend/src/infrastructure/intelligent_cache.rs:                query_key: "user:user1".to_string(),
./backend/src/infrastructure/intelligent_cache.rs:                query_key: "user:user2".to_string(),
./backend/src/infrastructure/intelligent_cache.rs:                query_key: "user:user3".to_string(),
./backend/src/infrastructure/intelligent_cache.rs:            let (query_type, key) = &workload[idx];
./backend/src/infrastructure/intelligent_cache.rs:            workload.push((query_type.clone(), key.clone()));
./backend/src/infrastructure/intelligent_cache.rs:        for (query_type, key) in workload {
./backend/src/infrastructure/intelligent_cache.rs:            let cache_key = CacheKey::Custom(format!("{}:{}", query_type, key));
./backend/src/infrastructure/intelligent_cache.rs:                .execute_cached_query(cache_key, vec![], || async {
./backend/src/infrastructure/streaming.rs:    pub fn with_metadata(mut self, key: String, value: String) -> Self {
./backend/src/infrastructure/streaming.rs:        self.metadata.insert(key, value);
./backend/src/infrastructure/monitoring/health_monitor.rs:        let agent_ids: Vec<Uuid> = self.agent_health.read().await.keys().cloned().collect();
./backend/src/infrastructure/monitoring/mod.rs:// Re-export key components
./backend/src/infrastructure/cache_optimization.rs:            let key = CacheKey::Custom(format!("benchmark_key_{}", operations % 1000));
./backend/src/infrastructure/cache_optimization.rs:                if let Err(e) = self.cache_manager.set_cached(key, cache_entry).await {
./backend/src/infrastructure/cache_optimization.rs:                    .get_cached::<serde_json::Value>(&key)
./backend/src/infrastructure/network_optimizer.rs:        let key = format!("{}:{}", host, port);
./backend/src/infrastructure/network_optimizer.rs:            if let Some(pool) = pools.get_mut(&key) {
./backend/src/infrastructure/network_optimizer.rs:        let key = format!("{}:{}", connection.host, connection.port);
./backend/src/infrastructure/network_optimizer.rs:        let pool = pools.entry(key).or_insert_with(Vec::new);
./backend/src/infrastructure/network_optimizer.rs:    tokens: Arc<Mutex<u64>>,
./backend/src/infrastructure/network_optimizer.rs:            tokens: Arc::new(Mutex::new(config.rate_limit_bytes_per_sec)),
./backend/src/infrastructure/network_optimizer.rs:        let mut tokens = self.tokens.lock().await;
./backend/src/infrastructure/network_optimizer.rs:        // Refill tokens based on elapsed time
./backend/src/infrastructure/network_optimizer.rs:        let tokens_to_add = (elapsed.as_secs_f64() * self.config.rate_limit_bytes_per_sec as f64) as u64;
./backend/src/infrastructure/network_optimizer.rs:        *tokens = (*tokens + tokens_to_add).min(self.config.rate_limit_bytes_per_sec);
./backend/src/infrastructure/network_optimizer.rs:        if *tokens >= requested_bytes as u64 {
./backend/src/infrastructure/network_optimizer.rs:            *tokens -= requested_bytes as u64;
./backend/src/infrastructure/performance_integration.rs:    pub async fn get_cached(&self, key: &str) -> Option<serde_json::Value> {
./backend/src/infrastructure/performance_integration.rs:        self.cache_manager.get(key).await
./backend/src/infrastructure/performance_integration.rs:    pub async fn set_cached(&self, key: String, value: serde_json::Value) -> HiveResult<()> {
./backend/src/infrastructure/performance_integration.rs:        self.cache_manager.set(key, value).await
./backend/src/infrastructure/performance_integration.rs:    pub async fn get_or_load<F, Fut>(&self, key: &str, loader: F) -> HiveResult<serde_json::Value>
./backend/src/infrastructure/performance_integration.rs:        if let Some(cached) = self.get_cached(key).await {
./backend/src/infrastructure/performance_integration.rs:        self.set_cached(key.to_string(), value.clone()).await?;
./backend/src/infrastructure/performance_integration.rs:            .get_or_load("new_key", || async {
./backend/src/infrastructure/intelligent_alerting.rs:            let alert_key = format!(
./backend/src/infrastructure/intelligent_alerting.rs:            if let Some(last_sent) = suppression.suppressed_alerts.get(&alert_key) {
./backend/src/infrastructure/intelligent_alerting.rs:            suppression.suppressed_alerts.insert(alert_key, now);
./backend/src/infrastructure/intelligent_alerting.rs:            .max_by_key(|(_, count)| *count)
./backend/performance_benchmark.rs:        let key = format!("key_{}", i);
./backend/performance_benchmark.rs:            map.insert(key, data);
./backend/bench_runner.rs:            for (key, value) in &result.custom_metrics {
./backend/bench_runner.rs:                println!("     {}: {:.2}", key, value);
./backend/benches/performance_optimizations.rs:                let key = format!("key_{}", i);
./backend/benches/performance_optimizations.rs:                cache.set(key.clone(), value.clone()).await.unwrap();
./backend/benches/performance_optimizations.rs:                    let _ = cache.get(&key).await;
./backend/benches/performance_optimizations.rs:                    .set_with_intelligence(key, value)
./backend/benches/performance_optimizations.rs:                if cache_manager.get_with_warming(&key).await.is_some() {
./backend/benches/performance_optimizations.rs:                let key = format!("hot_key_{}", i % 10); // High frequency keys
./backend/benches/performance_optimizations.rs:                    let _ = cache_manager.get_with_warming(&key).await;
./backend/simple_perf_benchmark.rs:                let key = format!("thread_{}_item_{}", i, j);
./backend/simple_perf_benchmark.rs:                map.insert(key, data);
./backend/simple_perf_benchmark.rs:        if map.contains_key(&i) {
./frontend/e2e/dashboard.spec.ts:    const metricsChanged = Object.keys(initialMetrics).some(key =>
./frontend/e2e/dashboard.spec.ts:      initialMetrics[key] !== updatedMetrics[key]
./frontend/src/hooks/useErrorRecovery.ts:        const isRetryable = retryableErrors.some(keyword => message.includes(keyword)) ||
./frontend/src/hooks/useErrorRecovery.ts:        const isNonRetryable = nonRetryableErrors.some(keyword => message.includes(keyword))
./frontend/scripts/agent-map.js:      Object.keys(agentMap.agents).length > 0
./frontend/scripts/agent-map.js:        ? totalConnections / Object.keys(agentMap.agents).length
./frontend/scripts/agent-map.js:    console.log(`   Total Agents: ${Object.keys(agentMap.agents).length}`)
./frontend/scripts/agent-behavior-decisions.js:    const agents = Object.keys(decisionPatterns.agent_decision_profiles)
./frontend/scripts/agent-behavior-communication.js:    commPatterns.patterns.isolated_agents = Object.keys(commPatterns.interaction_frequency).filter(
./frontend/.next/server/server-reference-manifest.js:self.__RSC_SERVER_MANIFEST="{\n  \"node\": {},\n  \"edge\": {},\n  \"encryptionKey\": \"process.env.NEXT_SERVER_ACTIONS_ENCRYPTION_KEY\"\n}"
./frontend/package-lock.json:        "@csstools/css-tokenizer": "^3.0.3",
./frontend/package-lock.json:        "js-tokens": "^4.0.0",
./frontend/package-lock.json:        "@csstools/css-tokenizer": "^3.0.4"
./frontend/package-lock.json:        "@csstools/css-tokenizer": "^3.0.4"
./frontend/package-lock.json:        "@csstools/css-tokenizer": "^3.0.4"
./frontend/package-lock.json:    "node_modules/@csstools/css-tokenizer": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/@csstools/css-tokenizer/-/css-tokenizer-3.0.4.tgz",
./frontend/package-lock.json:        "eslint-visitor-keys": "^3.4.3"
./frontend/package-lock.json:        "@typescript-eslint/visitor-keys": "8.42.0",
./frontend/package-lock.json:        "@typescript-eslint/visitor-keys": "8.42.0",
./frontend/package-lock.json:        "@typescript-eslint/visitor-keys": "8.42.0"
./frontend/package-lock.json:        "@typescript-eslint/visitor-keys": "8.42.0",
./frontend/package-lock.json:    "node_modules/@typescript-eslint/visitor-keys": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-8.42.0.tgz",
./frontend/package-lock.json:        "eslint-visitor-keys": "^4.2.1"
./frontend/package-lock.json:    "node_modules/@typescript-eslint/visitor-keys/node_modules/eslint-visitor-keys": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-4.2.1.tgz",
./frontend/package-lock.json:        "js-tokens": "^9.0.1"
./frontend/package-lock.json:    "node_modules/ast-v8-to-istanbul/node_modules/js-tokens": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-9.0.1.tgz",
./frontend/package-lock.json:        "path-key": "^3.1.0",
./frontend/package-lock.json:        "object-keys": "^1.1.1"
./frontend/package-lock.json:        "object-keys": "^1.1.1",
./frontend/package-lock.json:        "own-keys": "^1.0.1",
./frontend/package-lock.json:        "eslint-visitor-keys": "^3.4.3",
./frontend/package-lock.json:        "@typescript-eslint/visitor-keys": "7.18.0"
./frontend/package-lock.json:        "@typescript-eslint/visitor-keys": "7.18.0",
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-7.18.0.tgz",
./frontend/package-lock.json:        "eslint-visitor-keys": "^3.4.3"
./frontend/package-lock.json:    "node_modules/eslint-visitor-keys": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
./frontend/package-lock.json:        "eslint-visitor-keys": "^3.4.1"
./frontend/package-lock.json:        "keyv": "^4.5.3",
./frontend/package-lock.json:    "node_modules/js-tokens": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
./frontend/package-lock.json:    "node_modules/keyv": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
./frontend/package-lock.json:        "js-tokens": "^3.0.0 || ^4.0.0"
./frontend/package-lock.json:    "node_modules/object-keys": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/object-keys/-/object-keys-1.1.1.tgz",
./frontend/package-lock.json:        "object-keys": "^1.1.1"
./frontend/package-lock.json:    "node_modules/own-keys": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/own-keys/-/own-keys-1.0.1.tgz",
./frontend/package-lock.json:        "object-keys": "^1.1.1",
./frontend/package-lock.json:    "node_modules/path-key": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
./frontend/package-lock.json:        "js-tokens": "^9.0.1"
./frontend/package-lock.json:    "node_modules/strip-literal/node_modules/js-tokens": {
./frontend/package-lock.json:      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-9.0.1.tgz",
./frontend/package-lock.json:      "integrity": "sha512-nWJ91DjeOkej/TA8pXQ3myruKpKEYgqvpw9lz4OPHj/NWFNluYrjbz9j01CJ8yKQd2g4jFoOkINCTW2I5LEEyw==",
